{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59721f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da77bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from util.config_util import dotdict\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e806564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.uniform import Uniform\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a680595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "\n",
    "def shift_axis(distance_to_origin, scaler):\n",
    "    if scaler is None:\n",
    "        return distance_to_origin\n",
    "    scaled_offset = (\n",
    "        torch.mul(scaler, distance_to_origin[:, -1])\n",
    "        .unsqueeze(-1)\n",
    "        .expand(-1, distance_to_origin.shape[-1])\n",
    "    )\n",
    "    return torch.sub(distance_to_origin, scaled_offset)\n",
    "\n",
    "def noise_scale_sampling(device: str = \"cpu\"):\n",
    "    rand = np.random.rand()\n",
    "    if rand <= 0.4: \n",
    "        noise = Uniform(0, 0.2).sample()   # very low noise\n",
    "    elif rand <= 0.8:\n",
    "        noise = Uniform(0.3, 0.7).sample() # moderate noise\n",
    "    else:\n",
    "        noise = Uniform(0.8, 1.2).sample() # high noise\n",
    "\n",
    "    return noise.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8241ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperprior_params = dotdict({\n",
    "    'resolution_min': 25, 'resolution_max': 48, 'resolution_multiplier': 25,\n",
    "\n",
    "    'trend_lin_min': -0.6,  'trend_lin_max': 0.6,  'trend_lin_fixed_variance': 0.15,\n",
    "    'trend_exp_min': 1,  'trend_exp_max': 2, 'trend_exp_fixed_variance': 0.010,\n",
    "    'trend_exp_multiplier': 100,\n",
    "    'offset_lin_min': -0.5, 'offset_lin_max': 0.5,\n",
    "    'offset_exp_min': -0.5, 'offset_exp_max': 0.5,\n",
    "\n",
    "    'a_min': -1.5,  'a_max': 1.5,  'a_fixed_variance': 0.35,\n",
    "    'm_min': -3,  'm_max': 3,  'm_fixed_variance': 0.35,\n",
    "    'w_min': -6,  'w_max': 6,  'w_fixed_variance': 0.35,\n",
    "    'harmonics_min': 1,     'harmonics_max': 12,\n",
    "\n",
    "    'noise_k_min': 0.3,    'noise_k_max': 3,\n",
    "\n",
    "    'amplitude_min': 1.2,  'amplitude_max': 2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24456eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def _phase01(x: torch.Tensor, period: float) -> torch.Tensor:\n",
    "    # continuous phase in [0,1)\n",
    "    return torch.remainder(x, period) / period\n",
    "\n",
    "def get_freq_component(\n",
    "    phase01: torch.Tensor,          # normalized phase in [0,1)\n",
    "    n_harmonics: Union[int, torch.Tensor],\n",
    "    device: str = \"cpu\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    ") -> torch.Tensor:\n",
    "    H = int(n_harmonics if isinstance(n_harmonics, int) else n_harmonics.item())\n",
    "    B, T = phase01.shape\n",
    "    h = torch.arange(1, H + 1, device=device, dtype=dtype).view(1, H, 1)  # [1,H,1]\n",
    "    phi = phase01.to(device=device, dtype=dtype).unsqueeze(1)              # [B,1,T]\n",
    "\n",
    "    # random coefficients ~ N(0, 1/h), normalized\n",
    "    std = 1.0 / torch.arange(1, H + 1, device=device, dtype=dtype)\n",
    "    sin_c = torch.normal(mean=torch.zeros(H, device=device, dtype=dtype), std=std).view(1, H, 1)\n",
    "    cos_c = torch.normal(mean=torch.zeros(H, device=device, dtype=dtype), std=std).view(1, H, 1)\n",
    "    norm = torch.sqrt((sin_c ** 2 + cos_c ** 2).sum())  # scalar; stable scale across batches\n",
    "    sin_c /= norm\n",
    "    cos_c /= norm\n",
    "\n",
    "    sin = (sin_c * torch.sin(2 * math.pi * h * phi)).sum(dim=1)  # [B,T]\n",
    "    cos = (cos_c * torch.cos(2 * math.pi * h * phi)).sum(dim=1)  # [B,T]\n",
    "    return (sin + cos) / math.sqrt(2.0 * H)                      # zero-mean, unit-ish var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2298a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_hyperpriors(hyperprior_params, n_sequence, device):\n",
    "    hpp = hyperprior_params\n",
    "    \n",
    "    def _single_hier_normal(lo, hi, fixed_std):\n",
    "        mu = Uniform(lo, hi).sample().to(device)                # scalar\n",
    "        return Normal(mu, fixed_std).sample().to(device).view(1) # [1]\n",
    "\n",
    "    def _single_uniform(lo, hi):\n",
    "        return Uniform(lo, hi).sample().to(device).view(1)       # [1]\n",
    "    result = dotdict()\n",
    "\n",
    "    for param, min_val, max_val, fixed_variance in [\n",
    "        (\"annual_param\", hpp.a_min, hpp.a_max, hpp.a_fixed_variance),\n",
    "        (\"monthly_param\", hpp.m_min, hpp.m_max, hpp.m_fixed_variance),\n",
    "        (\"weekly_param\", hpp.w_min, hpp.w_max, hpp.w_fixed_variance),\n",
    "        (\"trend_lin\", hpp.trend_lin_min, hpp.trend_lin_max, hpp.trend_lin_fixed_variance),  # noqa\n",
    "    ]:\n",
    "        result[param] = _single_hier_normal(min_val, max_val, fixed_variance)\n",
    "\n",
    "\n",
    "    # make it equally likely to have a positive or negative exp trend\n",
    "\n",
    "    mm = hpp.trend_exp_multiplier\n",
    "    span_upper = n_sequence / hpp.resolution_min\n",
    "    mm_eff = mm / span_upper\n",
    "    f_exp      = lambda x: 2 ** ((x - 1) * mm_eff)\n",
    "    f_exp_inv  = lambda x: (torch.log2(x) / mm_eff) + 1\n",
    "\n",
    "\n",
    "    g_min = f_exp(torch.tensor(hpp.trend_exp_min, device=device))\n",
    "    g_max = f_exp(torch.tensor(hpp.trend_exp_max, device=device))\n",
    "    g     = _single_hier_normal(g_min, g_max, hpp.trend_exp_fixed_variance)  # factor, [1]\n",
    "    result.trend_exp = f_exp_inv(g)  # [1]\n",
    "\n",
    "    # ensure consistent sign for trends\n",
    "\n",
    "    median_lin_sign = result.trend_lin.median().sign()\n",
    "    result.trend_lin = result.trend_lin.abs() * median_lin_sign\n",
    "\n",
    "    assert (result.trend_lin >= 0).all() or (\n",
    "        result.trend_lin <= 0\n",
    "    ).all(), f\"non-consistent sign {result.trend_lin=} in trend_lin\"\n",
    "\n",
    "    median_exp_sign = (result.trend_exp - 1).median().sign()\n",
    "    result.trend_exp = (result.trend_exp - 1).abs() * median_exp_sign + 1\n",
    "\n",
    "    assert (result.trend_exp >= 1).all() or (\n",
    "        result.trend_exp <= 1\n",
    "    ).all(), f\"non-consistent {result.trend_exp=} in trend_exp\"\n",
    "\n",
    "    # sub-context-specific params\n",
    "\n",
    "    result.noise_k = _single_uniform(hpp.noise_k_min, hpp.noise_k_max)\n",
    "\n",
    "    result.noise_scale = noise_scale_sampling(device=device)\n",
    "\n",
    "    # domain-specific params\n",
    "    result.amplitude    = _single_uniform(hpp.amplitude_min, hpp.amplitude_max)\n",
    "    result.offset_lin = _single_uniform(hpp.offset_lin_min, hpp.offset_lin_max)\n",
    "    result.offset_exp = _single_uniform(hpp.offset_exp_min, hpp.offset_exp_max)\n",
    "    result.harmonics = torch.randint(hpp.harmonics_min, hpp.harmonics_max, (3,), device=device)\n",
    "\n",
    "    # keep the n-days at a set median\n",
    "    mm = hpp.resolution_multiplier\n",
    "    f_res = lambda x: torch.log2(x * mm + 1)\n",
    "    f_res_inv = lambda x: (2**x - 1) / mm\n",
    "\n",
    "    rmin = f_res(torch.tensor(hpp.resolution_min, device=device))\n",
    "    rmax = f_res(torch.tensor(hpp.resolution_max, device=device))\n",
    "    result.resolution = f_res_inv(Uniform(rmin, rmax).sample().to(device)).view(1)    # [1]\n",
    "\n",
    "    result.n_units = torch.ceil(n_sequence / result.resolution)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b64e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_exp_scaler = 0.00001\n",
    "def get_shift_and_span(x):\n",
    "    B, T = x.shape\n",
    "    origin = x[:, 0].unsqueeze(-1).expand(B, T)\n",
    "    distance_to_origin = torch.sub(x, origin)\n",
    "    span = (x[:, -1] - x[:, 0]).unsqueeze(-1).expand_as(x).clamp_min(1e-8)\n",
    "    return distance_to_origin, span\n",
    "\n",
    "def gen_linear_trend(x, trend_lin, offset_lin, distance_to_origin, span):\n",
    "    B, T = x.shape\n",
    "    linear_trend = torch.zeros_like(x)\n",
    "    \n",
    "    trend_linear_scaler = trend_lin.unsqueeze(-1).expand(B, T)\n",
    "    linear_trend = torch.mul(\n",
    "        shift_axis(distance_to_origin, offset_lin) / span, trend_linear_scaler\n",
    "    )\n",
    "    return linear_trend\n",
    "\n",
    "def gen_exp_trend(x, trend_exp, offset_exp, distance_to_origin, span):\n",
    "    B, T = x.shape\n",
    "    log_base = torch.log(trend_exp.clip(min=min_exp_scaler)).unsqueeze(-1).expand(B, T)\n",
    "    exponent = shift_axis(distance_to_origin, offset_exp) / span\n",
    "    log_term = (log_base * exponent).clamp(min=-20.0, max=20.0)\n",
    "    exp_trend = torch.exp(log_term)\n",
    "    return exp_trend\n",
    "\n",
    "def gen_trend(x, trend_lin, offset_lin, trend_exp, offset_exp):\n",
    "    distance_to_origin, span = get_shift_and_span(x)\n",
    "    \n",
    "    trend_comp_total = torch.ones_like(x)\n",
    "    \n",
    "    linear_trend = gen_linear_trend(x, trend_lin, offset_lin, distance_to_origin, span)\n",
    "    trend_comp_total = torch.add(trend_comp_total, linear_trend)\n",
    "    \n",
    "    exp_trend = gen_exp_trend(x, trend_exp, offset_exp, distance_to_origin, span)\n",
    "    trend_comp_total = torch.mul(trend_comp_total, exp_trend)\n",
    "    \n",
    "    return trend_comp_total, linear_trend, exp_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e583de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(x, noise_k, noise_scale, trend_comp_total, tau=3.0):\n",
    "    B, T = x.shape\n",
    "    k = noise_k.clamp_min(1e-6)\n",
    "    lambda_med = 1.0 / (torch.log(torch.tensor(2.0)) ** (1.0 / k))\n",
    "    wb = torch.distributions.Weibull(\n",
    "        concentration=k.unsqueeze(-1).expand(B, T),\n",
    "        scale=lambda_med.unsqueeze(-1).expand(B, T)\n",
    "        )\n",
    "    weibull_noise_term = wb.sample()\n",
    "    delta = torch.tanh((weibull_noise_term - 1.0) / tau)        # ∈ (-1, 1)\n",
    "    \n",
    "    lvl_mean = trend_comp_total.abs().mean(dim=1, keepdim=True).add(1e-6)   # [B,1]\n",
    "    lvl = (trend_comp_total.abs() / lvl_mean).clamp(0.1, 10.0).sqrt()       # [B,T]\n",
    "    noise = 1 + noise_scale.unsqueeze(-1) * delta * lvl\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ca965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seasonal_component(comp_type, x, amp, n_harmonics):\n",
    "    _PERIOD = {\"weekly\": 7.0, \"monthly\": 30.417, \"annual\": 365.25}\n",
    "    period = _PERIOD[comp_type]\n",
    "    base = get_freq_component(_phase01(x, period), n_harmonics, device=x.device.type, dtype=x.dtype)  # [B,T]\n",
    "    return 1 + amp.unsqueeze(-1) * base\n",
    "def gen_seasonal(x, n_harmonics, annual_param, monthly_param, weekly_param, cap=0.5, eps=1e-6):\n",
    "    B, T = x.shape\n",
    "    device, dtype = x.device, x.dtype\n",
    "\n",
    "    total = torch.ones(B, T, device=device, dtype=dtype)\n",
    "\n",
    "    total.mul_(gen_seasonal_component('annual',  x, annual_param,  n_harmonics[0]))\n",
    "    total.mul_(gen_seasonal_component('monthly', x, monthly_param, n_harmonics[1]))\n",
    "    total.mul_(gen_seasonal_component('weekly',  x, weekly_param,  n_harmonics[2]))\n",
    "    z = total - total.mean(dim=1, keepdim=True)\n",
    "    z = z / (total.std(dim=1, keepdim=True) + eps)\n",
    "    s = 1.0 + cap * torch.tanh(z)                      # strictly positive, bounded\n",
    "    s = s / (s.mean(dim=1, keepdim=True) + eps)        # mean 1\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d5139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _series_from_params(p, n_sequence, device):\n",
    "    T = n_sequence\n",
    "    lin = torch.linspace(0, 1, T, device=device)                 # [T]\n",
    "    x = p.n_units.to(device)[:, None] * lin[None, :]             # [1, T]\n",
    "\n",
    "    trend_comp, _, _ = gen_trend(\n",
    "        x,\n",
    "        trend_lin=p.trend_lin, offset_lin=p.offset_lin,\n",
    "        trend_exp=p.trend_exp, offset_exp=p.offset_exp\n",
    "    )                                                             # [1, T]\n",
    "\n",
    "    total_seasonality = gen_seasonal(\n",
    "        x, n_harmonics=p.harmonics,\n",
    "        annual_param=p.annual_param, monthly_param=p.monthly_param, weekly_param=p.weekly_param\n",
    "    )                                                             # [1, T]\n",
    "\n",
    "    amp   = p.amplitude.to(device).unsqueeze(-1)                  # [1,1]\n",
    "    noise = gen_noise(x, noise_k=p.noise_k, noise_scale=p.noise_scale, trend_comp_total=trend_comp)\n",
    "    v = amp * trend_comp * total_seasonality * noise              # [1, T]\n",
    "    return v.squeeze(0)                                           # [T]\n",
    "\n",
    "def gen_series():\n",
    "    n_sequence = 12000\n",
    "    component_params = sample_from_hyperpriors(hyperprior_params, n_sequence, device)\n",
    "    return _series_from_params(component_params, n_sequence, device)\n",
    "gen_series().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81264356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b105cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_units(resolution_min, resolution_max, resolution_multiplier,\n",
    "                   n_sequence=12000, n_samples=20000, seed=0):\n",
    "    torch.manual_seed(int(seed))\n",
    "    mm = float(resolution_multiplier)\n",
    "\n",
    "    # transforms\n",
    "    f_res     = lambda x: torch.log2(x * mm + 1.0)\n",
    "    f_res_inv = lambda x: (2.0**x - 1.0) / mm\n",
    "\n",
    "    # bounds in transformed space\n",
    "    rmin = f_res(torch.tensor(float(resolution_min), dtype=torch.float32))\n",
    "    rmax = f_res(torch.tensor(float(resolution_max), dtype=torch.float32))\n",
    "\n",
    "    # sample resolution in transformed space, map back\n",
    "    u = torch.distributions.Uniform(rmin, rmax).sample((int(n_samples),))\n",
    "    resolution = f_res_inv(u)  # [n_samples]\n",
    "\n",
    "    # discrete n_units\n",
    "    n_units = torch.ceil(torch.tensor(float(n_sequence)) / resolution)  # [n_samples]: float tensor with integer values\n",
    "    vmin = int(n_units.min().item())\n",
    "    vmax = int(n_units.max().item())\n",
    "    \n",
    "    uniq, counts = torch.unique(n_units, sorted=True, return_counts=True)\n",
    "    probs = counts.float() / counts.sum()\n",
    "    mode = int(uniq[counts.argmax()].item())\n",
    "    unique_ct = int(uniq.numel())\n",
    "    entropy = float(-(probs * torch.log2(probs + 1e-12)).sum().item())\n",
    "    \n",
    "    x = n_units.float()\n",
    "    mean = x.mean().item()\n",
    "    std  = x.std(unbiased=False).item()\n",
    "    q05, q50, q95 = torch.quantile(x, torch.tensor([0.05, 0.5, 0.95])).tolist()\n",
    "    stats = {\n",
    "        \"uniq\": uniq, \"counts\": counts, \"mode\": mode, \"unique_ct\": unique_ct, \"probs\": probs, \"entropy\": entropy,\n",
    "        \"vmin\": vmin, \"vmax\": vmax, \"mean\": mean, \"std\": std, \"q05\": q05, \"q50\": q50, \"q95\": q95\n",
    "    }\n",
    "    return n_units, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f14ff53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _theoretical_bounds(resolution_min, resolution_max, resolution_multiplier, n_sequence):\n",
    "    mm = float(resolution_multiplier)\n",
    "    f_res     = lambda x: torch.log2(x * mm + 1.0)\n",
    "    f_res_inv = lambda x: (2.0**x - 1.0) / mm\n",
    "    # min n_units occurs at largest resolution, and vice versa\n",
    "    lo = math.ceil(n_sequence / f_res_inv(f_res(torch.tensor(float(resolution_max)))).item())\n",
    "    hi = math.ceil(n_sequence / f_res_inv(f_res(torch.tensor(float(resolution_min)))).item())\n",
    "    return int(lo), int(hi)\n",
    "\n",
    "def plot_n_units_with_stats(resolution_min, resolution_max, resolution_multiplier,\n",
    "                            n_sequence=12000, n_samples=20000, seed=0):\n",
    "    n_units, stats = sample_n_units(resolution_min, resolution_max, resolution_multiplier,\n",
    "                             n_sequence=n_sequence, n_samples=n_samples, seed=seed)\n",
    "\n",
    "    lo_th, hi_th = _theoretical_bounds(resolution_min, resolution_max, resolution_multiplier, n_sequence)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    plt.bar(stats[\"uniq\"].numpy(), stats[\"probs\"].numpy(), width=0.9, align=\"center\")\n",
    "    plt.xlabel(\"n_units\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(f\"Distribution of n_units (N={int(n_samples)})\")\n",
    "    plt.axvline(lo_th, linestyle=\"--\")\n",
    "    plt.axvline(hi_th, linestyle=\"--\")\n",
    "    plt.tight_layout()\n",
    "    q05, q50, q95 = stats[\"q05\"], stats[\"q50\"], stats[\"q95\"]\n",
    "\n",
    "    md = (\n",
    "        f\"**n_units stats**\\n\\n\"\n",
    "        f\"- theoretical min-max: {lo_th} - {hi_th}\\n\"\n",
    "        f\"- min-max: {stats['vmin']} - {stats['vmax']}\\n\"\n",
    "        f\"- mean: {stats['mean']:.3f}, std: {stats['std']:.3f}\\n\"\n",
    "        f\"- mode: {stats['mode']}  (unique values: {stats['unique_ct']})\\n\"\n",
    "        f\"- q05/median/q95: {q05:.1f} / {q50:.1f} / {q95:.1f}\\n\"\n",
    "        f\"- Step size Δx ~ q05/median/q95: {(q05 / n_sequence):.3f} / {(q50 / n_sequence):.3f} / {(q95 / n_sequence):.3f}\\n\"\n",
    "        f\"- entropy (bits): {stats['entropy']:.3f}\\n\"\n",
    "        f\"(max entropy = {math.log2(stats['unique_ct']):.3f})\"\n",
    "    )\n",
    "    opts = [f\"Min: {stats['vmin']}\", f\"Median: {int(round(stats['q50']))}\", f\"Max: {stats['vmax']}\"]\n",
    "    # return a ComponentUpdate for the Radio\n",
    "    radio_update = gr.update(choices=opts, value=opts[1], label=\"Select n_units\")\n",
    "    return fig, md, radio_update, radio_update, radio_update, radio_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b948379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_trends(\n",
    "    n_units_choice, n_sequence: int = 12000, n_samples: int = 20000, seed: int = 0, \n",
    "    # trend param bounds\n",
    "    trend_lin_min: float = -0.02, offset_lin_min: float = -0.5, trend_exp_min: float = 1.0, offset_exp_min: float = -0.5,\n",
    "    trend_lin_max: float = 0.02,  offset_lin_max: float = 0.5,  trend_exp_max: float = 2.0,  offset_exp_max: float = 0.5,\n",
    "):\n",
    "    \n",
    "    n_units = torch.as_tensor([float(n_units_choice.split()[-1])]) # [1]\n",
    "\n",
    "    T = int(n_sequence)\n",
    "    lin = torch.linspace(0.0, 1.0, T)  # [T]\n",
    "    x = n_units[:, None] * lin[None, :]\n",
    "\n",
    "    distance_to_origin, span = get_shift_and_span(x)\n",
    "    offset_lin_dict = {\"min\": offset_lin_min, \"avg\": 0.5 * (offset_lin_min + offset_lin_max), \"max\": offset_lin_max}\n",
    "    offset_exp_dict = {\"min\": offset_exp_min, \"avg\": 0.5 * (offset_exp_min + offset_exp_max), \"max\": offset_exp_max}\n",
    "    trend_lin_vals  = np.linspace(trend_lin_min, trend_lin_max, 5)  # 5 lines per panel\n",
    "    trend_exp_vals  = np.linspace(trend_exp_min, trend_exp_max, 5)\n",
    "\n",
    "    fig_lin, axes_lin = plt.subplots(3, 1, figsize=(10, 9), sharex=True)\n",
    "    for i, (okey, ovalue) in enumerate(offset_lin_dict.items()):\n",
    "        ax = axes_lin[i]\n",
    "        stats_lines = []\n",
    "        for tl in trend_lin_vals:\n",
    "            tl_t = torch.tensor([tl], dtype=torch.float32)\n",
    "            ol_t = torch.tensor([ovalue], dtype=torch.float32)\n",
    "            lt = gen_linear_trend(x, tl_t, ol_t, distance_to_origin, span).squeeze(0)  # [T]\n",
    "            y = lt.detach().cpu().numpy()\n",
    "            ax.plot(range(T), y, label=f\"trend_lin={tl:.3f}\")\n",
    "            stats_lines.append(f\"lin={tl:+.3f} → mean={y.mean():+.3g}, std={y.std():.3g}, min={y.min():+.3g}, max={y.max():+.3g}\")\n",
    "        ax.set_title(f\"offset_lin={okey} ({ovalue:+.3f})\")\n",
    "        ax.set_ylabel(\"linear_trend\")\n",
    "        ax.legend(fontsize=8, ncol=3)\n",
    "        ax.text(0.0, -0.35, \"\\n\".join(stats_lines), transform=ax.transAxes, fontsize=8, va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    axes_lin[-1].set_xlabel(\"t\")\n",
    "    fig_lin.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    fig_exp, axes_exp = plt.subplots(3, 1, figsize=(10, 9), sharex=True)\n",
    "    for i, (okey, ovalue) in enumerate(offset_exp_dict.items()):\n",
    "        ax = axes_exp[i]\n",
    "        stats_lines = []\n",
    "        for te in trend_exp_vals:\n",
    "            te_t = torch.tensor([te], dtype=torch.float32)\n",
    "            oe_t = torch.tensor([ovalue], dtype=torch.float32)\n",
    "            et = gen_exp_trend(x, te_t, oe_t, distance_to_origin, span).squeeze(0)  # [T]\n",
    "            y = et.detach().cpu().numpy()\n",
    "            ax.plot(range(T), y, label=f\"trend_exp={te:.3f}\")\n",
    "            stats_lines.append(f\"exp={te:+.3f} → mean={y.mean():+.3g}, std={y.std():.3g}, min={y.min():+.3g}, max={y.max():+.3g}\")\n",
    "        ax.set_title(f\"offset_exp={okey} ({ovalue:+.3f})\")\n",
    "        ax.set_ylabel(\"exp_trend\")\n",
    "        ax.legend(fontsize=8, ncol=3)\n",
    "        ax.text(0.0, -0.35, \"\\n\".join(stats_lines), transform=ax.transAxes, fontsize=8, va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    axes_exp[-1].set_xlabel(\"t\")\n",
    "    fig_exp.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    ol_avg = torch.tensor([offset_lin_dict['avg']], dtype=torch.float32)\n",
    "    oe_avg = torch.tensor([offset_exp_dict['avg']], dtype=torch.float32)\n",
    "    tl_min = torch.tensor([trend_lin_min], dtype=torch.float32)\n",
    "    tl_max = torch.tensor([trend_lin_max], dtype=torch.float32)\n",
    "\n",
    "    fig_tot, axes_tot = plt.subplots(3, 2, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    rep_trends = {}\n",
    "    combos = [\n",
    "        (0, 0, 0), # \"low-low-low\"\n",
    "        (0, 4, 2), # \"low-high-high\"\n",
    "        (1, 0, 2), # \"high-low-high\" \n",
    "        (1, 4, 0), # \"high-high-low\"\n",
    "    ]\n",
    "    for r, (okey, ovalue) in enumerate(offset_exp_dict.items()):\n",
    "        for c, (tl_lbl, tl_val) in enumerate([(\"min\", tl_min), (\"max\", tl_max)]):\n",
    "            ax = axes_tot[r, c]\n",
    "            stats_lines = []\n",
    "            for t, te in enumerate(trend_exp_vals):\n",
    "                te_t = torch.tensor([te], dtype=torch.float32)\n",
    "                oe_t = torch.tensor([ovalue], dtype=torch.float32)\n",
    "                total, lin_comp, exp_comp = gen_trend(x, tl_val, ol_avg, te_t, oe_t)  # [1,T]\n",
    "                y = total.squeeze(0).detach().cpu().numpy()\n",
    "                if (c, t, r) in combos: \n",
    "                    rep_trends[(c, t, r)] = y\n",
    "                ax.plot(range(T), y, label=f\"trend_exp={te:.3f}\")\n",
    "                stats_lines.append(f\"tot(tl={tl_lbl}, exp={te:+.3f}) → mean={y.mean():+.3g} std={y.std():.3g} \"\n",
    "                                   f\"min={y.min():+.3g} max={y.max():+.3g}\")\n",
    "            ax.set_title(f\"offset_exp={okey} ({ovalue:+.3f}) | trend_lin={tl_lbl} ({tl_val.item():+.3f})\")\n",
    "            ax.set_ylabel(\"total_trend\")\n",
    "            if r == 2:\n",
    "                ax.set_xlabel(\"t\")\n",
    "            ax.legend(fontsize=8, ncol=3)\n",
    "            ax.text(0.0, -0.35, \"\\n\".join(stats_lines), transform=ax.transAxes, fontsize=8,\n",
    "                    va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    fig_tot.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    \n",
    "    tl_avg, te_avg = torch.tensor([trend_lin_vals[2]], dtype=torch.float32), torch.tensor([trend_exp_vals[2]], dtype=torch.float32)\n",
    "    tot, _, _ = gen_trend(x, tl_avg, ol_avg, te_avg, oe_avg)    # center\n",
    "    rep_trends[(2, 2, 1)] = tot.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    return fig_lin, fig_exp, fig_tot, rep_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa3d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seasonality_components(\n",
    "    n_units_choice, n_sequence: int = 12_000,\n",
    "    a: float = 3.0, m: float = 6.0, w: float = 9.0,     # amplitude bounds\n",
    "    harmonics_min: int = 2, harmonics_max: int = 12,    # harmonics bounds\n",
    "):\n",
    "    a_min, a_max = -a, a\n",
    "    m_min, m_max = -m, m\n",
    "    w_min, w_max = -w, w\n",
    "    # timeline\n",
    "    n_units = torch.as_tensor([float(n_units_choice.split()[-1])])  # [1]\n",
    "    T = int(n_sequence)\n",
    "    lin = torch.linspace(0.0, 1.0, T)                               # [T]\n",
    "    x = n_units[:, None] * lin[None, :]                              # [1,T]\n",
    "    device, dtype = x.device, x.dtype\n",
    "\n",
    "    # midpoints\n",
    "    a_avg, m_avg, w_avg = 0.5 * (a_min + a_max), 0.5 * (m_min + m_max), 0.5 * (w_min + w_max)\n",
    "    h_avg = int(0.5 * (harmonics_min + harmonics_max))\n",
    "\n",
    "    a_vals, m_vals, w_vals = np.linspace(a_min, a_max, 5), np.linspace(m_min, m_max, 5), np.linspace(w_min, w_max, 5)\n",
    "    h_vals = [harmonics_min, h_avg, harmonics_max]\n",
    "\n",
    "    fig_ann, axes_ann = plt.subplots(3, 1, figsize=(10, 16), sharex=True)\n",
    "    for i, hv in enumerate(h_vals):\n",
    "        ax = axes_ann[i]\n",
    "        stats = []\n",
    "        for v in a_vals:\n",
    "            pv = torch.tensor([v], dtype=dtype)\n",
    "            comp = gen_seasonal_component('annual', x, pv, hv).squeeze(0).cpu().numpy()\n",
    "            ax.plot(range(T), comp, label=f\"a={v:+.2f}, h={hv}\")\n",
    "            stats.append(f\"{v:+.2f} → mean={comp.mean():+.3g} std={comp.std():.3g} min={comp.min():+.3g} max={comp.max():+.3g}\")\n",
    "        ax.set_title(f\"Annual component — harmonics={hv}\")\n",
    "        ax.legend(fontsize=8, ncol=3)\n",
    "        ax.text(0.0, -0.35, \"\\n\".join(stats), transform=ax.transAxes, fontsize=8,\n",
    "                va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    axes_ann[-1].set_xlabel(\"t\")\n",
    "    fig_ann.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    fig_mon, axes_mon = plt.subplots(3, 1, figsize=(10, 16), sharex=True)\n",
    "    for i, hv in enumerate(h_vals):\n",
    "        ax = axes_mon[i]\n",
    "        stats = []\n",
    "        for v in m_vals:\n",
    "            pv = torch.tensor([v], dtype=dtype)\n",
    "            comp = gen_seasonal_component('monthly', x, pv, hv).squeeze(0).cpu().numpy()\n",
    "            ax.plot(range(T), comp, label=f\"m={v:+.2f}, h={hv}\")\n",
    "            stats.append(f\"{v:+.2f} → mean={comp.mean():+.3g} std={comp.std():.3g} min={comp.min():+.3g} max={comp.max():+.3g}\")\n",
    "        ax.set_title(f\"Monthly component — harmonics={hv}\")\n",
    "        ax.legend(fontsize=8, ncol=3)\n",
    "        ax.text(0.0, -0.35, \"\\n\".join(stats), transform=ax.transAxes, fontsize=8,\n",
    "                va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    axes_mon[-1].set_xlabel(\"t\")\n",
    "    fig_mon.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    fig_wek, axes_wek = plt.subplots(3, 1, figsize=(10, 16), sharex=True)\n",
    "    for i, hv in enumerate(h_vals):\n",
    "        ax = axes_wek[i]\n",
    "        stats = []\n",
    "        for v in w_vals:\n",
    "            pv = torch.tensor([v], dtype=dtype)\n",
    "            comp = gen_seasonal_component('weekly', x, pv, hv).squeeze(0).cpu().numpy()\n",
    "            ax.plot(range(T), comp, label=f\"w={v:+.2f}, h={hv}\")\n",
    "            stats.append(f\"{v:+.2f} → mean={comp.mean():+.3g} std={comp.std():.3g} min={comp.min():+.3g} max={comp.max():+.3g}\")\n",
    "        ax.set_title(f\"Weekly component — harmonics={hv}\")\n",
    "        ax.legend(fontsize=8, ncol=3)\n",
    "        ax.text(0.0, -0.35, \"\\n\".join(stats), transform=ax.transAxes, fontsize=8,\n",
    "                va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    axes_wek[-1].set_xlabel(\"t\")\n",
    "    fig_wek.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    # Fix two amplitudes at their midpoints, sweep the third; repeat for h in {min,avg,max}\n",
    "    fig_tot, axes_tot = plt.subplots(3, 3, figsize=(20, 10), sharex=True, sharey=False)\n",
    "    sweeps = [\n",
    "        ('annual',  a_vals, ('monthly','weekly')),\n",
    "        ('monthly', m_vals, ('annual','weekly')),\n",
    "        ('weekly',  w_vals, ('annual','monthly')),\n",
    "    ]\n",
    "    rep_seasonal = {}\n",
    "    name_list = ['min', 'avg', 'max']\n",
    "    for r, hv in enumerate(h_vals):\n",
    "        for c, (name, vals, _) in enumerate(sweeps):\n",
    "            ax = axes_tot[r, c]\n",
    "            stats = []\n",
    "            for t, v in enumerate(vals):\n",
    "                a = torch.tensor([a_max], dtype=dtype)\n",
    "                m = torch.tensor([m_max], dtype=dtype)\n",
    "                w = torch.tensor([w_max], dtype=dtype)\n",
    "                if name == 'annual':  a = torch.tensor([v], dtype=dtype)\n",
    "                if name == 'monthly': m = torch.tensor([v], dtype=dtype)\n",
    "                if name == 'weekly':  w = torch.tensor([v], dtype=dtype)\n",
    "                ha = hv if name == 'annual'  else h_avg\n",
    "                hm = hv if name == 'monthly' else h_avg\n",
    "                hw = hv if name == 'weekly'  else h_avg\n",
    "                total = gen_seasonal(x, (ha, hm, hw), a, m, w).squeeze(0).cpu().numpy()\n",
    "                if t == 4:\n",
    "                    rep_seasonal[(name_list[r], 'max')] = total\n",
    "                ax.plot(range(T), total, label=f\"{name}={v:+.2f}\")\n",
    "                stats.append(f\"{v:+.2f} → mean={total.mean():+.3g} std={total.std():.3g} min={total.min():+.3g} max={total.max():+.3g}\")\n",
    "            ax.set_title(f\"Total — sweep {name} amp @ its harmonics={hv}\")\n",
    "            if r == 2:\n",
    "                ax.set_xlabel(\"t\")\n",
    "            ax.legend(fontsize=7, ncol=3)\n",
    "            ax.text(0.0, -0.35, \"\\n\".join(stats), transform=ax.transAxes, fontsize=8,\n",
    "                    va=\"top\", ha=\"left\", family=\"monospace\")\n",
    "    fig_tot.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    for r, hv in enumerate(h_vals):\n",
    "        total = gen_seasonal(x, (hv, hv, hv), torch.tensor([a_min], dtype=dtype), torch.tensor([m_min], dtype=dtype), torch.tensor([w_min], dtype=dtype)).squeeze(0).cpu().numpy()\n",
    "        rep_seasonal[(name_list[r], 'min')] = total\n",
    "    return fig_ann, fig_mon, fig_wek, fig_tot, rep_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0eec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise(\n",
    "    n_units_choice,\n",
    "    n_sequence: int = 12_000,\n",
    "    noise_k_min: float = 0.3,\n",
    "    noise_k_max: float = 3.0,\n",
    "    trend_bases = None,\n",
    "    scale_levels = (0.1, 0.5, 1.0), # representative scales for three buckets (very low, moderate, high)\n",
    "):\n",
    "    n_units = torch.as_tensor([float(n_units_choice.split()[-1])])  # [1]\n",
    "    T = int(n_sequence)\n",
    "    lin = torch.linspace(0.0, 1.0, T)\n",
    "    x = n_units[:, None] * lin[None, :]                              # [1,T]\n",
    "    device, dtype = x.device, x.dtype\n",
    "    figs = []\n",
    "    rep_noise = {}\n",
    "    for name, trend in trend_bases.items():\n",
    "        trend_comp_total = torch.tensor(trend, dtype=torch.float32).unsqueeze(0)\n",
    "        if trend_comp_total is None:\n",
    "            trend_comp_total = torch.ones_like(x)                        # [1,T]\n",
    "\n",
    "        k_vals = np.linspace(noise_k_min, noise_k_max, 5)\n",
    "\n",
    "        # rows = 3 noise_scale levels, cols = 5 values\n",
    "        fig, axes = plt.subplots(len(scale_levels), 5, figsize=(2.7*7, 2.7*len(scale_levels)), sharex=True, sharey=False)\n",
    "        if len(scale_levels) == 1: axes = np.expand_dims(axes, 0)\n",
    "        for r, scale in enumerate(scale_levels):\n",
    "            for c, kv in enumerate(k_vals):\n",
    "                ax = axes[r, c]\n",
    "                k_t = torch.full((1,), float(kv),  device=device, dtype=dtype)     # [B]\n",
    "                s_t = torch.full((1,), float(scale), device=device, dtype=dtype)   # [B]\n",
    "                y = gen_noise(x, k_t, s_t, trend_comp_total).squeeze(0).cpu().numpy()\n",
    "                ax.plot(range(T), y)\n",
    "                if r == 0:\n",
    "                    ax.set_title(f\"k={kv:.2f}\")\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(f\"scale={scale:.2f}\")\n",
    "                if r == len(scale_levels)-1:\n",
    "                    ax.set_xlabel(\"t\")\n",
    "                    if c in (0, 4):\n",
    "                        rep_noise[(name, c)] = y\n",
    "                ax.text(0.02, 0.02,\n",
    "                        f\"mean={y.mean():+.3g} std={y.std():.3g} min={y.min():+.3g} max={y.max():+.3g}\",\n",
    "                        transform=ax.transAxes, fontsize=7, family=\"monospace\")\n",
    "        fig.suptitle(\"Multiplicative noise component: rows=scale, cols=noise_k\")\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "        figs.append(fig)\n",
    "    return figs + [rep_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e35300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams(resolution_min, resolution_max, resolution_multiplier,\n",
    "                    trend_lin_min, trend_lin_max, offset_lin_min, offset_lin_max,\n",
    "                    trend_exp_min, trend_exp_max, offset_exp_min, offset_exp_max,\n",
    "                    a, m, w, harmonics_min, harmonics_max,\n",
    "                    noise_k_min, noise_k_max, amplitude_min, amplitude_max):\n",
    "    return f\"\"\"'resolution_min': {resolution_min}, 'resolution_max': {resolution_max}, 'resolution_multiplier': {resolution_multiplier},\n",
    "\n",
    "'trend_lin_min': {trend_lin_min},  'trend_lin_max': {trend_lin_max},  'trend_lin_fixed_variance': 0.15,\n",
    "'trend_exp_min': {trend_exp_min},  'trend_exp_max': {trend_exp_max}, 'trend_exp_fixed_variance': 0.010,\n",
    "'trend_exp_multiplier': 100,\n",
    "'offset_lin_min': {offset_lin_min}, 'offset_lin_max': {offset_lin_max},\n",
    "'offset_exp_min': {offset_exp_min}, 'offset_exp_max': {offset_exp_max},\n",
    "\n",
    "'a_min': {-a},  'a_max': {a},  'a_fixed_variance': 0.35,\n",
    "'m_min': {-m},  'm_max': {m},  'm_fixed_variance': 0.35,\n",
    "'w_min': {-w},  'w_max': {w},  'w_fixed_variance': 0.35,\n",
    "'harmonics_min': {harmonics_min},     'harmonics_max': {harmonics_max},\n",
    "\n",
    "'noise_k_min': {noise_k_min},    'noise_k_max': {noise_k_max},\n",
    "\n",
    "'amplitude_min': {amplitude_min},  'amplitude_max': {amplitude_max}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ab771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_bt(arr):\n",
    "    t = torch.as_tensor(arr, dtype=torch.float32)\n",
    "    if t.ndim == 1: t = t.unsqueeze(0)   # [1,T]\n",
    "    return t\n",
    "def plot_total_series(n_units_choice, n_sequence, \n",
    "                      amplitude_min, amplitude_max,\n",
    "                      trend_choice, seasonal_choice, harmonics_choice,\n",
    "                      trend_bases_state, seasonal_state, noise_state):\n",
    "    trend_map = {\"low-low-low\": (0, 0, 0),\n",
    "                 \"low-high-high\": (0, 4, 2),\n",
    "                 \"high-low-high\" : (1, 0, 2),\n",
    "                 \"high-high-low\": (1, 4, 0),\n",
    "                 \"center\": (2, 2, 1)}\n",
    "    seasonal_map = {'Min', 'Max'}\n",
    "    n_units = torch.as_tensor([float(n_units_choice.split()[-1])])  # [1]\n",
    "    T = int(n_sequence)\n",
    "    lin = torch.linspace(0.0, 1.0, T)                               # [T]\n",
    "    x = n_units[:, None] * lin[None, :]                              # [1,T]\n",
    "    \n",
    "    trend_comp_arr = trend_bases_state[trend_map[trend_choice]]\n",
    "    trend  = _to_bt(trend_comp_arr)           # [1,T]\n",
    "    \n",
    "    season_total_arr = seasonal_state[(harmonics_choice, seasonal_choice)]\n",
    "    season = _to_bt(season_total_arr)         # [1,T]\n",
    "    T = trend.shape[1]\n",
    "    amp = torch.tensor([amplitude_min]).unsqueeze(-1)   # [1,1]\n",
    "\n",
    "    # noiseless baseline\n",
    "    base = amp * trend * season                        # [1,T]\n",
    "    \n",
    "    n_min = noise_state[(trend_map[trend_choice], 0)]\n",
    "    n_max = noise_state[(trend_map[trend_choice], 4)]\n",
    "\n",
    "    y0 = base.squeeze(0).cpu().numpy()                 # noiseless\n",
    "    yA = (base * _to_bt(n_min)).squeeze(0).cpu().numpy()       # noisy @ k_min\n",
    "    yB = (base * _to_bt(n_max)).squeeze(0).cpu().numpy()       # noisy @ k_max\n",
    "\n",
    "    # components to display (noise factors only, not applied)\n",
    "    tr_np = trend.squeeze(0).cpu().numpy()\n",
    "    se_np = season.squeeze(0).cpu().numpy()\n",
    "\n",
    "    # layout: 4 rows, 3 cols; row 0 has 3 panels; rows 1–3 span all cols\n",
    "    fig = plt.figure(figsize=(14, 10), constrained_layout=True)\n",
    "    outer = fig.add_gridspec(nrows=4, ncols=1, height_ratios=[1, 1, 1, 1])\n",
    "    top = outer[0].subgridspec(1, 3, wspace=0.08)\n",
    "\n",
    "    ax_tr   = fig.add_subplot(top[0, 0])\n",
    "    ax_se   = fig.add_subplot(top[0, 1])\n",
    "    ax_noise= fig.add_subplot(top[0, 2])\n",
    "\n",
    "    ax_y0   = fig.add_subplot(outer[1, :])\n",
    "    ax_yA   = fig.add_subplot(outer[2, :])\n",
    "    ax_yB   = fig.add_subplot(outer[3, :])\n",
    "\n",
    "\n",
    "    # components row\n",
    "    ax_tr.plot(range(T), tr_np);      ax_tr.set_title(\"Trend component\")\n",
    "    ax_se.plot(range(T), se_np);      ax_se.set_title(\"Seasonality component\")\n",
    "    ax_noise.plot(range(T), n_min, label=f\"min noise_k\")\n",
    "    ax_noise.plot(range(T), n_max, label=f\"max noise_k\")\n",
    "    ax_noise.set_title(f\"Noise factors\")\n",
    "    ax_noise.legend(fontsize=8)\n",
    "\n",
    "    # final series rows\n",
    "    ax_y0.plot(range(T), y0); ax_y0.set_title(\"Final — noiseless\")\n",
    "    ax_yA.plot(range(T), yA); ax_yA.set_title(f\"Final — noisy @ min noise_k\")\n",
    "    ax_yB.plot(range(T), yB); ax_yB.set_title(f\"Final — noisy @ max noise_k\")\n",
    "    ax_yB.set_xlabel(\"t\")\n",
    "\n",
    "    # fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13e1f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_196349/831761618.py\", line 20, in plot_total_series\n",
      "    trend_comp_arr = trend_bases_state[trend_map[trend_choice]]\n",
      "KeyError: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_196349/831761618.py\", line 20, in plot_total_series\n",
      "    trend_comp_arr = trend_bases_state[trend_map[trend_choice]]\n",
      "KeyError: None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/queueing.py\", line 789, in process_events\n",
      "    await run_sync(self.compute_analytics_summary, self.event_analytics)\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2405, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 914, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/queueing.py\", line 177, in compute_analytics_summary\n",
      "    df = self._get_df(event_analytics)\n",
      "  File \"/home/lvu/playground/ts-project/venv/lib/python3.10/site-packages/gradio/queueing.py\", line 166, in _get_df\n",
      "    pd.DataFrame(list(event_analytics.values()))\n",
      "TypeError: NDFrame.infer_objects() got an unexpected keyword argument 'copy'\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    trend_bases_state = gr.State()\n",
    "    seasonal_state = gr.State()\n",
    "    noise_state = gr.State()\n",
    "    with gr.Tab(\"n_units\"):\n",
    "        with gr.Row():\n",
    "            resolution_multiplier = gr.Slider(1, 50, 25, step=1, label=\"Resolution Multiplier\")\n",
    "            resolution_min = gr.Slider(1, 365, 25, step=1, label=\"Min Resolution\")\n",
    "            resolution_max = gr.Slider(1, 365, 75, step=1, label=\"Max Resolution\")\n",
    "        with gr.Row():\n",
    "            n_sequence = gr.Slider(128, 50000, 12000, step=128, label=\"n_sequence\")\n",
    "            n_samples = gr.Slider(1000, 200000, 20000, step=1000, label=\"num samples\")\n",
    "            seed = gr.Slider(0, 10_000, 0, step=1, label=\"seed\")\n",
    "        btn_n_units = gr.Button(\"Plot + Stats\")\n",
    "        with gr.Row():\n",
    "            n_units_plot = gr.Plot(label=\"n_units distribution\", scale=2)\n",
    "            n_units_stats = gr.Markdown()\n",
    "    with gr.Tab(\"Trend\"):\n",
    "        trend_radio = gr.Radio([], label=\"Generate n_units first\")\n",
    "        with gr.Column(visible=False) as trend_panel:\n",
    "            with gr.Row():\n",
    "                trend_lin_min = gr.Slider(-5, 5, value=-2.0, step=0.05, label=\"trend_lin_min\")\n",
    "                trend_lin_max = gr.Slider(-3, 7, value=2.0,  step=0.05, label=\"trend_lin_max\")\n",
    "            with gr.Row():\n",
    "                offset_lin_min = gr.Slider(-2.0, 2.0, value=-1.5, step=0.01, label=\"offset_lin_min\")\n",
    "                offset_lin_max = gr.Slider(-2.0, 2.0, value=1.5,  step=0.01, label=\"offset_lin_max\")\n",
    "            with gr.Row():\n",
    "                trend_exp_min = gr.Slider(0.50, 6.00, value=2.0, step=0.01, label=\"trend_exp_min\")\n",
    "                trend_exp_max = gr.Slider(0.50, 8.00, value=4.0, step=0.01, label=\"trend_exp_max\")\n",
    "            with gr.Row():\n",
    "                offset_exp_min = gr.Slider(-2.0, 2.0, value=-1.5, step=0.01, label=\"offset_exp_min\")\n",
    "                offset_exp_max = gr.Slider(-2.0, 2.0, value=1.5,  step=0.01, label=\"offset_exp_max\")\n",
    "\n",
    "            btn_trend = gr.Button(\"Generate Trend Components\")\n",
    "            \n",
    "            with gr.Tabs():\n",
    "                with gr.TabItem(\"Linear Trend\"):\n",
    "                    linear_trend_plot = gr.Plot(label=\"linear_trend\")\n",
    "                with gr.TabItem(\"Exponential Trend\"):\n",
    "                    exp_trend_plot = gr.Plot(label=\"exp_trend\")\n",
    "                with gr.TabItem(\"Total Trend\"):\n",
    "                    total_trend_plot = gr.Plot(label=\"trend_total\")\n",
    "        \n",
    "        def _on_radio_change(choice):\n",
    "            return gr.update(visible=(choice is not None))\n",
    "        trend_radio.change(_on_radio_change, inputs=trend_radio, outputs=trend_panel)\n",
    "        \n",
    "    with gr.Tab(\"Seasonal\"):\n",
    "        seasonal_radio = gr.Radio([], label=\"Generate n_units first\")\n",
    "        with gr.Column(visible=False) as season_panel:\n",
    "            with gr.Row():\n",
    "                a = gr.Slider(0, 20.0, value=2, step=0.1, label=\"a\")\n",
    "                m = gr.Slider(0, 20.0, value=4, step=0.1, label=\"m\")\n",
    "                w = gr.Slider(0, 20.0, value=8, step=0.1, label=\"w\")\n",
    "            with gr.Row():\n",
    "                harmonics_min = gr.Slider(0, 10, value=1, step=1, label=\"harmonics_min\")\n",
    "                harmonics_max = gr.Slider(1, 20, value=12,  step=1, label=\"harmonics_max\")\n",
    "            btn_season = gr.Button(\"Generate Seasonal Components\")\n",
    "            \n",
    "            with gr.Tabs():\n",
    "                with gr.TabItem(\"Annual Seasonal\"):\n",
    "                    annual_comp_plot = gr.Plot(label=\"annual_comp\")\n",
    "                with gr.TabItem(\"Monthly Seasonal\"):\n",
    "                    monthly_comp_plot = gr.Plot(label=\"monthly_comp\")\n",
    "                with gr.TabItem(\"Weekly Seasonal\"):\n",
    "                    weekly_comp_plot = gr.Plot(label=\"weekly_comp\")\n",
    "                with gr.TabItem(\"Total Seasonal\"):\n",
    "                    total_comp_plot = gr.Plot(label=\"total_comp\")\n",
    "        seasonal_radio.change(_on_radio_change, inputs=seasonal_radio, outputs=season_panel)\n",
    "    \n",
    "    with gr.Tab(\"Noise\"):\n",
    "        noise_radio = gr.Radio([], label=\"Generate n_units first\")\n",
    "        with gr.Column(visible=False) as noise_panel:\n",
    "            with gr.Row():\n",
    "                noise_k_min = gr.Slider(0.1, 5.0, value=1.3, step=0.1, label=\"noise_k_min\")\n",
    "                noise_k_max = gr.Slider(0.2, 8.0, value=3.0, step=0.1, label=\"noise_k_max\")\n",
    "            btn_noise = gr.Button(\"Generate Noise\")\n",
    "            noise_plot_list = [None] * 5\n",
    "            with gr.Tabs():\n",
    "                for i, label in enumerate([\"low-low-low\", \"low-high-high\", \"high-low-high\", \"high-high-low\", \"center\"]):\n",
    "                    with gr.TabItem(\"Base Trend: \" + label):\n",
    "                        noise_plot_list[i] = gr.Plot(label=f'noise_from_{label}')\n",
    "        noise_radio.change(_on_radio_change, inputs=noise_radio, outputs=noise_panel)\n",
    "        \n",
    "    with gr.Tab(\"Total\"):\n",
    "        btn_gen_hpp = gr.Button(\"Get Hyperparams\")\n",
    "        hpp_text = gr.Textbox(lines=5)\n",
    "        total_radio = gr.Radio([], label=\"Generate n_units first\")\n",
    "        with gr.Column(visible=False) as total_panel:\n",
    "            with gr.Row():\n",
    "                amplitude_min = gr.Slider(0.1, 3.0, value=1.0, step=0.1, label=\"amplitude_min\")\n",
    "                amplitude_max = gr.Slider(0.2, 5.0, value=3.0, step=0.1, label=\"amplitude_max\")\n",
    "            trend_total_radio = gr.Radio(['low-low-low', 'low-high-high', 'high-low-high', 'high-high-low', 'center'], label=\"Pick trend\")\n",
    "            with gr.Row():\n",
    "                seasonal_total_radio = gr.Radio(['min', 'max'], label=\"Pick seasonality\")\n",
    "                harmonic_total_radio = gr.Radio(['min', 'avg', 'max'], label=\"Pick n_harmonics\")\n",
    "            btn_total = gr.Button(\"Generate Final Series\")\n",
    "            total_plot = gr.Plot(label=\"total_series\")\n",
    "            \n",
    "        total_radio.change(_on_radio_change, inputs=total_radio, outputs=total_panel)\n",
    "        btn_gen_hpp.click(fn=get_hyperparams,\n",
    "                          inputs=[resolution_min, resolution_max, resolution_multiplier, \n",
    "                                  trend_lin_min, trend_lin_max, offset_lin_min, offset_lin_max, \n",
    "                                  trend_exp_min, trend_exp_max, offset_exp_min, offset_exp_max, \n",
    "                                  a, m, w, harmonics_min, harmonics_max, \n",
    "                                  noise_k_min, noise_k_max, amplitude_min, amplitude_max],\n",
    "                          outputs=hpp_text)\n",
    "    \n",
    "    btn_n_units.click(\n",
    "        fn=plot_n_units_with_stats,\n",
    "        inputs=[resolution_min, resolution_max, resolution_multiplier, n_sequence, n_samples, seed],\n",
    "        outputs=[n_units_plot, n_units_stats, trend_radio, seasonal_radio, noise_radio, total_radio]\n",
    "    )\n",
    "    btn_trend.click(\n",
    "        fn=plot_trends,\n",
    "        inputs=[trend_radio, n_sequence, n_samples, seed, \n",
    "                trend_lin_min, offset_lin_min, trend_exp_min, offset_exp_min, \n",
    "                trend_lin_max, offset_lin_max, trend_exp_max, offset_exp_max],\n",
    "        outputs=[linear_trend_plot, exp_trend_plot, total_trend_plot, trend_bases_state]\n",
    "    )\n",
    "    btn_season.click(\n",
    "        fn=plot_seasonality_components,\n",
    "        inputs=[seasonal_radio, n_sequence, a, m, w, harmonics_min, harmonics_max],\n",
    "        outputs=[annual_comp_plot, monthly_comp_plot, weekly_comp_plot, total_comp_plot, seasonal_state]\n",
    "    )\n",
    "    btn_noise.click(\n",
    "        fn=plot_noise,\n",
    "        inputs=[noise_radio, n_sequence, noise_k_min, noise_k_max, trend_bases_state],\n",
    "        outputs=noise_plot_list + [noise_state]\n",
    "    )\n",
    "    btn_total.click(\n",
    "        fn=plot_total_series,\n",
    "        inputs=[total_radio, n_sequence, amplitude_min, amplitude_max, trend_total_radio, seasonal_total_radio, harmonic_total_radio, trend_bases_state, seasonal_state, noise_state],\n",
    "        outputs=[total_plot]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70697d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15faf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperprior_params = dotdict({'resolution_min': 25, 'resolution_max': 75, 'resolution_multiplier': 25,\n",
    "\n",
    "'trend_lin_min': -2,  'trend_lin_max': 2,  'trend_lin_fixed_variance': 0.15,\n",
    "'trend_exp_min': 2,  'trend_exp_max': 4, 'trend_exp_fixed_variance': 0.010,\n",
    "'trend_exp_multiplier': 100,\n",
    "'offset_lin_min': -1.5, 'offset_lin_max': 1.5,\n",
    "'offset_exp_min': -1.5, 'offset_exp_max': 1.5,\n",
    "\n",
    "'a_min': -2,  'a_max': 2,  'a_fixed_variance': 0.35,\n",
    "'m_min': -4,  'm_max': 4,  'm_fixed_variance': 0.35,\n",
    "'w_min': -8,  'w_max': 8,  'w_fixed_variance': 0.35,\n",
    "'harmonics_min': 1,     'harmonics_max': 12,\n",
    "\n",
    "'noise_k_min': 1.3,    'noise_k_max': 3,\n",
    "\n",
    "'amplitude_min': 1,  'amplitude_max': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, glob\n",
    "from pathlib import Path\n",
    "\n",
    "n_sequence = 12_000\n",
    "out_dir   = \"series_bank/v2\"\n",
    "n_series  = 1_000_000\n",
    "shard_sz  = 20_000\n",
    "dtype     = np.float32\n",
    "seed      = 42\n",
    "device    = \"cpu\"\n",
    "\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "torch.manual_seed(seed); np.random.seed(seed)\n",
    "\n",
    "# snapshot meta for reproducibility\n",
    "meta = {\n",
    "    \"n_series\": n_series,\n",
    "    \"shard_size\": shard_sz,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"seed\": seed,\n",
    "    \"n_sequence\": n_sequence,\n",
    "    \"hyperprior_params\": dict(hyperprior_params),\n",
    "}\n",
    "Path(out_dir, \"meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "n_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4583bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_shards: 100%|██████████| 50/50 [1:01:19<00:00, 73.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected (quick std): 0\n",
      "Rejected (patch clip): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- strict constants ---\n",
    "L, H = 512, 96\n",
    "CLIP = 10.0\n",
    "STD_MIN = 0.02\n",
    "PATCH_S = 64\n",
    "MAX_RETRIES = 12\n",
    "n_series  = 1_000_000\n",
    "n_sequence = 12000\n",
    "\n",
    "num_shards = math.ceil(n_series / shard_sz)\n",
    "idx = 0\n",
    "rej_quick = rej_patch = 0\n",
    "\n",
    "for s in tqdm(range(num_shards), desc='num_shards'):\n",
    "    k = min(shard_sz, n_series - idx)\n",
    "    buf = np.empty((k, n_sequence), dtype=dtype)\n",
    "\n",
    "    for i in tqdm(range(k), desc='k', leave=False):\n",
    "        accepted = False\n",
    "        for tries in range(MAX_RETRIES):\n",
    "            # synth\n",
    "            y = gen_series()\n",
    "            y = y.contiguous().float()\n",
    "\n",
    "            # quick series-level gate on context region\n",
    "            ctx_len = int(0.8 * n_sequence)\n",
    "            y_ctx = y[:ctx_len]\n",
    "            if y_ctx.std().item() < STD_MIN:\n",
    "                rej_quick += 1\n",
    "                continue\n",
    "\n",
    "            # subsampled patch-level saturation test\n",
    "            if ctx_len - (L + H) > 0:\n",
    "                ends = torch.linspace(L-1, ctx_len-1-H, PATCH_S).long()\n",
    "                Xs = torch.stack([y[e-L+1:e+1] for e in ends], dim=0)\n",
    "                Zs = torch.stack([y[e+1:e+1+H] for e in ends], dim=0)\n",
    "                mu = Xs.mean()\n",
    "                med = Xs.median()\n",
    "                mad = (Xs - med).abs().median()\n",
    "                sigma = (1.4826 * mad).clamp_min(1e-9)   # no 0.10 floor here\n",
    "                Zn = torch.clamp((Zs - mu) / sigma, -CLIP, CLIP)\n",
    "                clip_frac = (Zn.abs() == CLIP).float().mean().item()\n",
    "                if clip_frac > 0.25:\n",
    "                    rej_patch += 1\n",
    "                    continue\n",
    "\n",
    "            accepted = True\n",
    "            break\n",
    "\n",
    "        if not accepted:\n",
    "            # keep drawing until finite; skip stats gates, but require finiteness\n",
    "            while True:\n",
    "                y = gen_series()\n",
    "                y = y.contiguous().float()\n",
    "                if torch.isfinite(y).all():\n",
    "                    break\n",
    "\n",
    "        buf[i] = y.cpu().numpy().astype(dtype)\n",
    "\n",
    "    np.save(Path(out_dir, f\"series_shard_{s:04d}.npy\"), buf)\n",
    "    idx += k\n",
    "\n",
    "print(f\"Rejected (quick std): {rej_quick}\")\n",
    "print(f\"Rejected (patch clip): {rej_patch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_json = json.dumps(meta, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "log_dir = f'../tb_test/series_bank_v2'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Metadata\", meta_json, 0)\n",
    "writer.add_text(\"Notes\", \"New version\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
