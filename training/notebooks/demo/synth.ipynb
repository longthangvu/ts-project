{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d6946ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0499d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from util.config_util import ShapeConfig, dotdict\n",
    "from data.priors.LaTPFN_dataset import LaTPFNDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperprior_params= dotdict({\n",
    "    \"a_min\": -12.0, \"a_max\": 12.0,  \"a_fixed_variance\": 0.15,\n",
    "    \"m_min\": -6.0,  \"m_max\": 6.0,   \"m_fixed_variance\": 0.15,\n",
    "    \"w_min\": -3.0,  \"w_max\": 3.0,   \"w_fixed_variance\": 0.15,\n",
    "    \"trend_lin_min\": -0.015,  \"trend_lin_max\": 0.015,   \"trend_lin_fixed_variance\": 0.005,\n",
    "    \"trend_exp_min\": 0.995,   \"trend_exp_max\": 1.005,   \"trend_exp_fixed_variance\": 0.001,\n",
    "    \"trend_exp_multiplier\": 400,\n",
    "    \"noise_k_min\": 0.5,   \"noise_k_max\": 3.5,\n",
    "    \"resolution_min\": 0.1,  \"resolution_max\": 1.2,  \"resolution_multiplier\": 50,\n",
    "    \"harmonics_min\": 2,   \"harmonics_max\": 8,\n",
    "    \"discreteness_min\": 1,  \"discreteness_max\": 6,\n",
    "    \"bias_zi_min\": 0.8,   \"bias_zi_max\": 3.0,\n",
    "    \"amplitude_min\": 0.5,   \"amplitude_max\": 4.0,\n",
    "    \"non_negative_prob\": 0.2,\n",
    "    \"offset_lin_min\": -1.0,   \"offset_lin_max\": 1.2,\n",
    "    \"offset_exp_min\": -1.5,   \"offset_exp_max\": 2.0,\n",
    "    \"f_zi_min\": 0.0,    \"f_zi_max\": 0.6,  \"f_zi_fixed_variance\": 0.3\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51720eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_config = ShapeConfig(\n",
    "    n_context=2,\n",
    "    n_sequence=2_000,  # Length of synthetic series\n",
    "    n_features=1,    # Univariate series\n",
    "    n_heldout=1,\n",
    "    n_prompt=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71623ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring kwargs: <data.priors.LaTPFN_dataset.LaTPFNDataset object at 0x78e1561b73d0> {}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "base_dataset = LaTPFNDataset(\n",
    "            shape=shape_config,\n",
    "            hyperprior_params=hyperprior_params,\n",
    "            batch_size=1,\n",
    "            length=shape_config.n_sequence,\n",
    "            is_train=False,\n",
    "            device=device,\n",
    "            return_components=False,\n",
    "            scale_noise=True,\n",
    "            separate_noise=False  # Single values only\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fee5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v, _ = base_dataset.get_a_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b5f9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.priors.LaTPFN_prior.sampling import (\n",
    "    double_sampling,\n",
    "    triple_sampling,\n",
    "    noise_scale_sampling,\n",
    ")\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d8facd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_hyperpriors(shape=shape_config):\n",
    "    hpp = hyperprior_params\n",
    "    n_context = shape.n_context\n",
    "    n_sequence = shape.n_sequence\n",
    "\n",
    "    result = dotdict()\n",
    "\n",
    "    for param, min_val, max_val, fixed_variance in [\n",
    "        (\"annual_param\", hpp.a_min, hpp.a_max, hpp.a_fixed_variance),\n",
    "        (\"monthly_param\", hpp.m_min, hpp.m_max, hpp.m_fixed_variance),\n",
    "        (\"weekly_param\", hpp.w_min, hpp.w_max, hpp.w_fixed_variance),\n",
    "        (\"frequency_zero_inflation\", hpp.f_zi_min, hpp.f_zi_max, hpp.f_zi_fixed_variance),  # noqa\n",
    "        (\"trend_lin\", hpp.trend_lin_min, hpp.trend_lin_max, hpp.trend_lin_fixed_variance),  # noqa\n",
    "    ]:\n",
    "        result[param] = triple_sampling(\n",
    "            hyperprior_min=min_val,\n",
    "            hyperprior_max=max_val,\n",
    "            fixed_variance=fixed_variance,\n",
    "            num_samples=n_context,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    # make it equally likely to have a positive or negative exp trend\n",
    "\n",
    "    mm = hpp.trend_exp_multiplier  \n",
    "    # f_exp = lambda x: 2 ** ((x - 1) * mm)\n",
    "    # f_exp_inv = lambda x: (torch.log2(x) / mm) + 1\n",
    "    \n",
    "    # shrink effective multiplier as series span grows to keep base^(time) bounded\n",
    "    # approximate upper span by n_sequence / resolution_min\n",
    "    span_upper = n_sequence / hpp.resolution_min\n",
    "    mm_eff = hpp.trend_exp_multiplier / span_upper\n",
    "    f_exp      = lambda x: 2 ** ((x - 1) * mm_eff)\n",
    "    f_exp_inv  = lambda x: (torch.log2(x) / mm_eff) + 1\n",
    "\n",
    "\n",
    "    result.trend_exp = f_exp_inv(\n",
    "        triple_sampling(\n",
    "            hyperprior_min=f_exp(torch.scalar_tensor(hpp.trend_exp_min)),\n",
    "            hyperprior_max=f_exp(torch.scalar_tensor(hpp.trend_exp_max)),\n",
    "            fixed_variance=hpp.trend_exp_fixed_variance,\n",
    "            num_samples=n_context,\n",
    "            device=device,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ensure consistent sign for trends\n",
    "\n",
    "    median_lin_sign = result.trend_lin.median().sign()\n",
    "    result.trend_lin = result.trend_lin.abs() * median_lin_sign\n",
    "\n",
    "    assert (result.trend_lin >= 0).all() or (\n",
    "        result.trend_lin <= 0\n",
    "    ).all(), f\"non-consistent sign {result.trend_lin=} in trend_lin\"\n",
    "\n",
    "    median_exp_sign = (result.trend_exp - 1).median().sign()\n",
    "    result.trend_exp = (result.trend_exp - 1).abs() * median_exp_sign + 1\n",
    "\n",
    "    assert (result.trend_exp >= 1).all() or (\n",
    "        result.trend_exp <= 1\n",
    "    ).all(), f\"non-consistent {result.trend_exp=} in trend_exp\"\n",
    "\n",
    "    # sub-context-specific params\n",
    "\n",
    "    result.noise_k = double_sampling(\n",
    "        hyperprior_min=hpp.noise_k_min,\n",
    "        hyperprior_max=hpp.noise_k_max,\n",
    "        num_samples=n_context,\n",
    "        device=device,\n",
    "    )\n",
    "    result.noise_scale = noise_scale_sampling(n_context, device=device)\n",
    "\n",
    "    # domain-specific params\n",
    "\n",
    "    result.discreteness = (\n",
    "        Uniform(hpp.discreteness_min, hpp.discreteness_max)\n",
    "        .sample([n_context])\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    result.bias_zi = (\n",
    "        Uniform(hpp.bias_zi_min, hpp.bias_zi_max).sample([n_context]).to(device)\n",
    "    )\n",
    "\n",
    "    result.amplitude = (\n",
    "        Uniform(hpp.amplitude_min, hpp.amplitude_max).sample([n_context]).to(device)\n",
    "    )\n",
    "\n",
    "    result.non_negative = (\n",
    "        Categorical(\n",
    "            torch.tensor([1 - hpp.non_negative_prob, hpp.non_negative_prob])\n",
    "        )\n",
    "        .sample()\n",
    "        .to(device)\n",
    "        .repeat(n_context)\n",
    "    )\n",
    "\n",
    "    result.offset_lin = (\n",
    "        Uniform(hpp.offset_lin_min, hpp.offset_lin_max)\n",
    "        .sample([n_context])\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    result.offset_exp = (\n",
    "        Uniform(hpp.offset_exp_min, hpp.offset_exp_max)\n",
    "        .sample([n_context])\n",
    "        .to(device)\n",
    "    )\n",
    "\n",
    "    result.harmonics = torch.randint(hpp.harmonics_min, hpp.harmonics_max, (3,)).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    # keep the n-days at a set median\n",
    "\n",
    "    mm = hpp.resolution_multiplier\n",
    "    f_res = lambda x: torch.log2(x * mm + 1)\n",
    "    f_res_inv = lambda x: (2**x - 1) / mm\n",
    "\n",
    "    result.resolution = (\n",
    "        f_res_inv(\n",
    "            Uniform(\n",
    "                f_res(torch.scalar_tensor(hpp.resolution_min)),\n",
    "                f_res(torch.scalar_tensor(hpp.resolution_max)),\n",
    "            ).sample()\n",
    "        )\n",
    "        .to(device)\n",
    "        .repeat(n_context)\n",
    "    )\n",
    "\n",
    "    result.n_units = torch.ceil(n_sequence / result.resolution)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e6f9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_params = sample_from_hyperpriors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "feb4d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.priors.LaTPFN_prior.series_components import (\n",
    "    generate_trend_component,\n",
    "    generate_seasonal_component,\n",
    "    generate_noise_component,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e45adb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_series(n_context: int, sequence_length: int, num_features: int,\n",
    "                         device: str, component_params: dotdict, return_components: bool = False,  # For debugging and visualization purposes\n",
    "                         scale_noise: bool = True, equal_spacing: bool = True,):\n",
    "    if not equal_spacing:\n",
    "        x = (\n",
    "            (\n",
    "                torch.rand(n_context, sequence_length, num_features, device=device)\n",
    "                * component_params.n_units.unsqueeze(-1).unsqueeze(-1)\n",
    "            )\n",
    "            .squeeze()\n",
    "            .to(device)\n",
    "        )\n",
    "\n",
    "        x, _ = torch.sort(x, dim=1)\n",
    "    else:\n",
    "        x = torch.linspace(0, 1, sequence_length, device=device).unsqueeze(0).repeat(\n",
    "            n_context, 1\n",
    "        ).unsqueeze(-1) * component_params.n_units.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = x.squeeze().to(device)\n",
    "\n",
    "    trend_comp_total, trend_comp_linear, trend_comp_exponential = (\n",
    "        generate_trend_component(\n",
    "            trend_linear_scaler=component_params.trend_lin,\n",
    "            trend_exp_scaler=component_params.trend_exp,\n",
    "            offset_linear=component_params.offset_lin,\n",
    "            offset_exp=component_params.offset_exp,\n",
    "            x=x,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    seasonal_components = generate_seasonal_component(\n",
    "        annual_param=component_params.annual_param,\n",
    "        monthly_param=component_params.monthly_param,\n",
    "        weekly_param=component_params.weekly_param,\n",
    "        x=x,\n",
    "        n_units=component_params.n_units,\n",
    "        n_harmonics=component_params.harmonics,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    total_seasonality, annual_seasonality, monthly_seasonality, weekly_seasonality = (\n",
    "        seasonal_components[:, :, 0],\n",
    "        seasonal_components[:, :, 1],\n",
    "        seasonal_components[:, :, 2],\n",
    "        seasonal_components[:, :, 3],\n",
    "    )\n",
    "    # total_seasonality = total_seasonality.clamp(0.1, 10.0)\n",
    "\n",
    "    # noisless_values = trend_comp_total * total_seasonality\n",
    "    noisless_values= component_params.amplitude[:, None] * (trend_comp_total * total_seasonality)\n",
    "\n",
    "    noise_mean = torch.ones_like(component_params.noise_k)\n",
    "\n",
    "    weibull_noise_term = generate_noise_component(\n",
    "        k=component_params.noise_k,\n",
    "        noise_mean=noise_mean,\n",
    "        shape=(x.shape[0], x.shape[1]),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    noise = 1 + component_params.noise_scale.unsqueeze(-1) * (\n",
    "        weibull_noise_term - noise_mean.unsqueeze(-1)\n",
    "    )\n",
    "\n",
    "    if scale_noise:\n",
    "        noise = noise * trend_comp_total\n",
    "        # lvl = (trend_comp_total / trend_comp_total.mean(dim=1, keepdim=True)).sqrt()\n",
    "        # noise = 1 + (lvl - 1) * component_params.noise_scale.unsqueeze(-1) * (\n",
    "        #     weibull_noise_term - noise_mean.unsqueeze(-1)\n",
    "        # )\n",
    "\n",
    "    return x, noisless_values, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5030c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v, noise = make_multiple_series(shape_config.n_context, shape_config.n_sequence, num_features=1, device=device, component_params=component_params, return_components=False, scale_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5ef8fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2000, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = (v * noise).unsqueeze(-1)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8848f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series = v[0, :, 0]\n",
    "y_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63bf1e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1924.3500,  3661.4334,  3324.3829,  ..., 26604.9522, 17117.8711,\n",
       "        21984.4842], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d108cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
