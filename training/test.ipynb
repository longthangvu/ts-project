{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1898df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7697de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805c88a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.ForecastPFN import ForecastPFN\n",
    "\n",
    "print('loading model')\n",
    "model = ForecastPFN()\n",
    "model.load_state_dict(torch.load('../synthetic-data/models/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffc50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(task_name='tradition_long_term_forecast', is_training=0, model_id='ili_36_24', model='naive_mean', data='ili', root_path='../../Time-Series-Library/dataset/illness/', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=18, pred_len=14, seasonal_patterns='Monthly', inverse=False, embed='timeF', e_layers=2, d_layers=1, factor=3, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, d_ff=2048, moving_avg=25, dropout=0.1, activation='gelu', expand=2, d_conv=4, distil=True, top_k=5, num_kernels=6, p_hidden_dims=[128, 128], p_hidden_layers=2, use_dtw=False, augmentation_ratio=0, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, gpu_type='cuda', use_multi_gpu=False, devices='0,1,2,3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ad3190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 180\n"
     ]
    }
   ],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "test_data, test_loader = data_provider(args, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73605870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ForecastPFN_time_features(ts: np.ndarray):\n",
    "        if type(ts[0]) == datetime.datetime:\n",
    "            year = [x.year for x in ts]\n",
    "            month = [x.month for x in ts]\n",
    "            day = [x.day for x in ts]\n",
    "            day_of_week = [x.weekday()+1 for x in ts]\n",
    "            day_of_year = [x.timetuple().tm_yday for x in ts]\n",
    "            return np.stack([year, month, day, day_of_week, day_of_year], axis=-1)\n",
    "        ts = pd.to_datetime(ts)\n",
    "        return np.stack([ts.year, ts.month, ts.day, ts.day_of_week + 1, ts.day_of_year], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900c4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d9189d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     print(\"CUDA is available! Using GPU.\")\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     print(\"CUDA is not available. Using CPU.\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18147901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_tuple(x,x_mark,y_mark, \n",
    "                    model, horizon):\n",
    "    \"\"\"\n",
    "    x: tensor of shape (n, 1)\n",
    "    x_mark: tensor of shape (n, d)\n",
    "    y_mark: tensor of shape (horizon, d)\n",
    "\n",
    "    where\n",
    "    n       is the input  sequence length\n",
    "    horizon is the output sequence length\n",
    "    d is the dimensionality of the time_stamp (5 for ForecastPFN)\n",
    "    \"\"\"\n",
    "    if torch.all(x == x[0]):\n",
    "        x[-1] += 1\n",
    "\n",
    "    history = x.cpu().numpy().reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(history)\n",
    "    history = scaler.transform(history)\n",
    "\n",
    "    history_mean = np.nanmean(history[-6:])\n",
    "    history_std = np.nanstd(history[-6:])\n",
    "    # local_scale = history_mean + history_std + 1e-4\n",
    "    local_scale = max(history_mean + history_std, 1e-4)\n",
    "    history = np.clip(history / local_scale, a_min=0, a_max=1)\n",
    "    history = np.nan_to_num(history, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "\n",
    "    n, d = x_mark.shape\n",
    "    if n != 100:\n",
    "        if n > 100:\n",
    "            target = x_mark[-100:, :]\n",
    "            history = torch.tensor(history[-100:], dtype=torch.float32)\n",
    "        else:\n",
    "            pad_len = 100 - n\n",
    "            target = torch.cat([torch.zeros(pad_len, d, dtype=x_mark.dtype, device=device), x_mark], dim=0)\n",
    "            history = torch.cat([\n",
    "                torch.zeros(pad_len, 1, dtype=torch.float32, device=device),\n",
    "                torch.tensor(history, dtype=torch.float32, device=device)\n",
    "            ], dim=0)\n",
    "\n",
    "        history = history.unsqueeze(0).repeat(horizon, 1, 1).squeeze(-1)\n",
    "        ts = target.unsqueeze(0).repeat(horizon, 1, 1)\n",
    "    else:\n",
    "        ts = x_mark.unsqueeze(0).repeat(horizon, 1, 1)\n",
    "        history = torch.tensor(history, dtype=torch.float32)\n",
    "\n",
    "    task = torch.ones(horizon, dtype=torch.long, device=device)\n",
    "    target_ts = y_mark[-horizon:, :].unsqueeze(1)\n",
    "    ts = ts.long()\n",
    "    target_ts = target_ts.long()\n",
    "\n",
    "\n",
    "    model_input = {\n",
    "        'ts': ts,\n",
    "        'history': history,\n",
    "        'target_ts': target_ts,\n",
    "        'task': task\n",
    "    }\n",
    "\n",
    "    t1 = time.time()\n",
    "    pred_vals = model(model_input)\n",
    "    # print('pred_vals:', pred_vals)\n",
    "    time_diff = time.time() - t1\n",
    "\n",
    "    scaled_vals = pred_vals['result'].detach().cpu().numpy().T.reshape(-1)\n",
    "    scales = pred_vals['scale'].detach().cpu().numpy().reshape(-1)\n",
    "    scaled_vals = scaler.inverse_transform([scaled_vals * scales])\n",
    "\n",
    "    return scaled_vals, time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c36b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ForecastPFN_process_batch(model, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for idx, (x, y, x_mark, y_mark) in enumerate(zip(batch_x, batch_y, batch_x_mark, batch_y_mark)):\n",
    "\n",
    "        pred, time_diff = _process_tuple(\n",
    "            x, x_mark, y_mark, model, args.pred_len)\n",
    "\n",
    "        y = y.unsqueeze(-1)[-args.pred_len:, :].to(device)\n",
    "        true = y.detach().cpu().numpy()\n",
    "        \n",
    "        preds += [pred]\n",
    "        trues += [true]\n",
    "    return preds, trues, time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32909f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e9dd6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (160, 1, 14) (160, 14, 1)\n",
      "test shape: (160, 1, 14) (160, 14, 1)\n",
      "mse:1.115865305300811, mae:0.8542831944643586, rmse:1.0563452585688122, mape:0.4291490448508656, mspe:0.4990638703813162\n"
     ]
    }
   ],
   "source": [
    "test_data.data_stamp = _ForecastPFN_time_features(\n",
    "    list(test_data.data_stamp_original['date']))\n",
    "model.eval()\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# def nan_hook(module, input, output):\n",
    "#     if isinstance(output, torch.Tensor) and torch.isnan(output).any():\n",
    "#         print(f\"NaN in {module.__class__.__name__}\")\n",
    "\n",
    "# for name, module in pretrained.named_modules():\n",
    "#     module.register_forward_hook(nan_hook)\n",
    "\n",
    "# folder_path = './test_results/' + setting + '/'\n",
    "# if not os.path.exists(folder_path):\n",
    "#     os.makedirs(folder_path)\n",
    "# print(folder_path)\n",
    "target_dim = 0\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "        # Move to device\n",
    "        batch_x = batch_x.float().to(device)              # [B, seq_len, D]\n",
    "        batch_y = batch_y.float().to(device)              # [B, label_len + pred_len, D]\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "        # Select target dimension only: shape [B, T]\n",
    "        x = batch_x[:, :, target_dim]                          # [B, seq_len]\n",
    "        y = batch_y[:, :, target_dim]                          # [B, label_len + pred_len]\n",
    "\n",
    "        # ForecastPFN expects input shape [B, T], not multivariate\n",
    "        pred, true, _ = _ForecastPFN_process_batch(\n",
    "            model, x, y, batch_x_mark, batch_y_mark\n",
    "        )\n",
    "\n",
    "        preds.append(pred)\n",
    "        trues.append(true)\n",
    "        input = batch_x.detach().cpu().numpy()\n",
    "        if test_data.scale and args.inverse:\n",
    "            shape = input.shape\n",
    "            input = test_data.inverse_transform(input.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "        true = np.array(true)\n",
    "        pred = np.array(pred)\n",
    "        # print('input shape:', input.shape)\n",
    "        # gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "        # pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "        # print()\n",
    "        # visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "trues = np.concatenate(trues, axis=0)\n",
    "print('test shape:', preds.shape, trues.shape)\n",
    "preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "print('test shape:', preds.shape, trues.shape)\n",
    "mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "print('mse:{}, mae:{}, rmse:{}, mape:{}, mspe:{}'.format(mse, mae, rmse, mape, mspe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
