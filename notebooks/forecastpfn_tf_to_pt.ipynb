{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to recreate ForecastPFN in Pytorch using its Tensorflow saved weights and implementation provided by the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c426d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 00:06:30.063569: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 00:06:30.066011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-04 00:06:30.066018: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/lvu/playground/ForecastPFN/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from benchmark.utils.metrics import smape\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1dd0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 00:06:35.014395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-04 00:06:35.015834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-06-04 00:06:35.044542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-06-04 00:06:35.044566: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-06-04 00:06:35.044868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " position_expansion (Positio  multiple                 0         \n",
      " nExpansion)                                                     \n",
      "                                                                 \n",
      " position_expansion_1 (Posit  multiple                 0         \n",
      " ionExpansion)                                                   \n",
      "                                                                 \n",
      " position_expansion_2 (Posit  multiple                 0         \n",
      " ionExpansion)                                                   \n",
      "                                                                 \n",
      " position_expansion_3 (Posit  multiple                 0         \n",
      " ionExpansion)                                                   \n",
      "                                                                 \n",
      " custom_scaling (CustomScali  multiple                 0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " NoPosEnc (Dense)            multiple                  72        \n",
      "                                                                 \n",
      " ForPosEnc (Dense)           multiple                  72        \n",
      "                                                                 \n",
      " ConcatPos (Concatenate)     multiple                  0         \n",
      "                                                                 \n",
      " ConcatEmbed (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  360       \n",
      "                                                                 \n",
      " AppendTarget (Concatenate)  multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 500040    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 997920    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " FinalOutput (Dense)         multiple                  289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,498,753\n",
      "Trainable params: 1,498,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model = tf.keras.models.load_model(\"saved_weights/\", custom_objects={'smape': smape})\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d4927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position_expansion\n",
      "position_expansion_1\n",
      "position_expansion_2\n",
      "position_expansion_3\n",
      "custom_scaling\n",
      "NoPosEnc\n",
      "  transformer_model/NoPosEnc/kernel:0 (1, 36)\n",
      "  transformer_model/NoPosEnc/bias:0 (36,)\n",
      "ForPosEnc\n",
      "  transformer_model/ForPosEnc/kernel:0 (1, 36)\n",
      "  transformer_model/ForPosEnc/bias:0 (36,)\n",
      "ConcatPos\n",
      "ConcatEmbed\n",
      "embedding\n",
      "  transformer_model/embedding/embeddings:0 (10, 36)\n",
      "AppendTarget\n",
      "transformer_block\n",
      "  transformer_model/transformer_block/transformer_block_attention/query/kernel:0 (72, 4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/query/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/key/kernel:0 (72, 4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/key/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/value/kernel:0 (72, 4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/value/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/attention_output/kernel:0 (4, 72, 72)\n",
      "  transformer_model/transformer_block/transformer_block_attention/attention_output/bias:0 (72,)\n",
      "  transformer_model/transformer_block/transformer_block_ff1/kernel:0 (72, 1152)\n",
      "  transformer_model/transformer_block/transformer_block_ff1/bias:0 (1152,)\n",
      "  transformer_model/transformer_block/transformer_block_ff2/kernel:0 (1152, 288)\n",
      "  transformer_model/transformer_block/transformer_block_ff2/bias:0 (288,)\n",
      "transformer_block_1\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/query/kernel:0 (288, 4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/query/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/key/kernel:0 (288, 4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/key/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/value/kernel:0 (288, 4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/value/bias:0 (4, 72)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/attention_output/kernel:0 (4, 72, 288)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_attention/attention_output/bias:0 (288,)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_ff1/kernel:0 (288, 1152)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_ff1/bias:0 (1152,)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_ff2/kernel:0 (1152, 288)\n",
      "  transformer_model/transformer_block_1/transformer_block_1_ff2/bias:0 (288,)\n",
      "FinalOutput\n",
      "  transformer_model/FinalOutput/kernel:0 (288, 1)\n",
      "  transformer_model/FinalOutput/bias:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "for layer in tf_model.layers:\n",
    "    print(layer.name)\n",
    "    for w in layer.weights:\n",
    "        print(\" \", w.name, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "layers = {l.name: l for l in tf_model.layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_input(B=2, context_len=100, target_len=1):\n",
    "    # ts: (B, context_len, 5) — year, month, day, dow, placeholder\n",
    "    ts = tf.constant(np.stack([\n",
    "        np.stack([\n",
    "            [2023, 1 + (i % 12), 1 + (i % 28), i % 7, 0]\n",
    "            for i in range(context_len)\n",
    "        ]) for _ in range(B)\n",
    "    ]), dtype=tf.int64)\n",
    "\n",
    "    # history: (B, context_len)\n",
    "    history = tf.random.normal((B, context_len), dtype=tf.float32)\n",
    "\n",
    "    # target_ts: (B, target_len, 5) — consistent with ts\n",
    "    target_ts = tf.constant(np.stack([\n",
    "        np.stack([\n",
    "            [2023, 1, 1, 0, 0]  # dummy future time\n",
    "        for _ in range(target_len)]) for _ in range(B)\n",
    "    ]), dtype=tf.int64)\n",
    "\n",
    "    # task: (B,)\n",
    "    task = tf.constant(np.random.randint(0, 10, size=(B,)), dtype=tf.int32)\n",
    "\n",
    "    return {\n",
    "        \"ts\": ts,\n",
    "        \"history\": history,\n",
    "        \"target_ts\": target_ts,\n",
    "        \"task\": task,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.0238485]\n",
      " [1.0556059]], shape=(2, 1), dtype=float32) tf.Tensor(\n",
      "[[1.2981894]\n",
      " [1.3832798]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mock_inputs = create_mock_input()\n",
    "output = tf_model(mock_inputs, training=False)\n",
    "\n",
    "# Extract from full model output\n",
    "full_result = output[\"result\"][:, :1]\n",
    "full_scale  = output[\"scale\"][:, :1]\n",
    "print(full_result, full_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 5) (2, 100) (2, 1, 5) (2,)\n",
      "<keras.layers.core.dense.Dense object at 0x75ae957db820> tf.Tensor(\n",
      "[[1.0238485]\n",
      " [1.0556059]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ts        = mock_inputs[\"ts\"]\n",
    "history   = mock_inputs[\"history\"]\n",
    "target_ts = mock_inputs[\"target_ts\"]\n",
    "task      = mock_inputs[\"task\"]\n",
    "print(ts.shape, history.shape, target_ts.shape, task.shape)\n",
    "epsilon = 1e-4\n",
    "# Extract layers\n",
    "position_expansion = layers[\"position_expansion\"]\n",
    "position_expansion_1 = layers[\"position_expansion_1\"]\n",
    "position_expansion_2 = layers[\"position_expansion_2\"]\n",
    "position_expansion_3 = layers[\"position_expansion_3\"]\n",
    "custom_scaling = layers[\"custom_scaling\"]\n",
    "no_pos_enc = layers[\"NoPosEnc\"]\n",
    "for_pos_enc = layers[\"ForPosEnc\"]\n",
    "concat_embed = layers[\"ConcatEmbed\"]\n",
    "append_target = layers[\"AppendTarget\"]\n",
    "embedding = layers[\"embedding\"]\n",
    "transformer_block_0 = layers[\"transformer_block\"]\n",
    "transformer_block_1 = layers[\"transformer_block_1\"]\n",
    "final_output = layers[\"FinalOutput\"]\n",
    "\n",
    "# ---- Block-by-block forward ----\n",
    "\n",
    "# 1. Position encoding\n",
    "year, month, day, dow = ts[:, :, 0], ts[:, :, 1], ts[:, :, 2], ts[:, :, 3]\n",
    "delta_year = tf.clip_by_value(year[:, -1:] - year, 0, 9)\n",
    "pos = tf.concat([\n",
    "    position_expansion(delta_year),\n",
    "    position_expansion_1(month),\n",
    "    position_expansion_2(day),\n",
    "    position_expansion_3(dow),\n",
    "], axis=-1)\n",
    "\n",
    "# 2. Scaling + history embedding\n",
    "history_channels = tf.expand_dims(history, -1)\n",
    "scale, scaled = custom_scaling(history_channels, epsilon)\n",
    "embed_nopos = no_pos_enc(scaled)\n",
    "embed_pos = for_pos_enc(scaled) + tf.cast(pos, tf.float32)\n",
    "embedded = concat_embed([embed_nopos, embed_pos])\n",
    "\n",
    "# 3. Target token\n",
    "target_year = tf.clip_by_value(year[:, -1:] - target_ts[:, :, 0], 0, 9)\n",
    "target_month, target_day, target_dow = target_ts[:, :, 1], target_ts[:, :, 2], target_ts[:, :, 3]\n",
    "target_pos = tf.concat([\n",
    "    position_expansion(target_year),\n",
    "    position_expansion_1(target_month),\n",
    "    position_expansion_2(target_day),\n",
    "    position_expansion_3(target_dow),\n",
    "], axis=-1)\n",
    "task_embed = embedding(task)\n",
    "target_token = concat_embed([task_embed, task_embed + tf.cast(tf.squeeze(target_pos, 1), tf.float32)])\n",
    "\n",
    "# 4. Append target token\n",
    "x = append_target([embedded, tf.expand_dims(target_token, axis=1)])\n",
    "\n",
    "# 5. Mask\n",
    "seq_mask = tf.cast(year > 0, tf.bool)\n",
    "seq_mask = tf.pad(seq_mask, [[0, 0], [0, 1]], constant_values=True)\n",
    "mask = tf.logical_and(tf.expand_dims(seq_mask, 1), tf.expand_dims(seq_mask, 2))\n",
    "\n",
    "# 6. Transformer blocks\n",
    "x = transformer_block_0(x, mask=mask, training=False)\n",
    "x = transformer_block_1(x, mask=mask, training=False)\n",
    "x = x[:, -1]\n",
    "\n",
    "# 7. Output\n",
    "rescaled = final_output(x) * tf.squeeze(scale[:, -1:], axis=-1)\n",
    "print(final_output, rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify manually-created version vs. original tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual forward output: [[1.0238485]\n",
      " [1.0556059]]\n",
      "Full model output    : [[1.0238485]\n",
      " [1.0556059]]\n",
      "Match (result): True\n",
      "Manual scale: [[[1.2981894]]\n",
      "\n",
      " [[1.3832798]]]\n",
      "Full scale  : [[1.2981894]\n",
      " [1.3832798]]\n",
      "Match (scale): True\n"
     ]
    }
   ],
   "source": [
    "print(\"Manual forward output:\", rescaled.numpy())\n",
    "print(\"Full model output    :\", full_result.numpy())\n",
    "print(\"Match (result):\", np.allclose(rescaled.numpy(), full_result.numpy(), atol=1e-5))\n",
    "\n",
    "manual_scale = np.squeeze(scale.numpy(), axis=-1)  # → shape (2, 1)\n",
    "print(\"Manual scale:\", scale[:, -1:].numpy())\n",
    "print(\"Full scale  :\", full_scale.numpy())\n",
    "print(\"Match (scale):\", np.allclose(manual_scale, full_scale.numpy(), atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate Components in Pytorch using Tensorflow Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mimic input in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 5]) torch.Size([2, 100]) torch.Size([2, 1, 5]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "def convert_tf_to_torch(tf_batch):\n",
    "    torch_batch = {}\n",
    "    for k, v in tf_batch.items():\n",
    "        torch_batch[k] = torch.from_numpy(v.numpy()).to(dtype=torch.float32 if v.dtype.is_floating else torch.long)\n",
    "    return torch_batch\n",
    "\n",
    "torch_input  = convert_tf_to_torch(mock_inputs)\n",
    "ts_pt        = torch_input['ts']\n",
    "history_pt   = torch_input['history']\n",
    "target_ts_pt = torch_input['target_ts']\n",
    "task_pt      = torch_input['task']\n",
    "print(ts_pt.shape, history_pt.shape, target_ts_pt.shape, task_pt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Input → Position Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 36])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow code\n",
    "year, month, day, dow = ts[:, :, 0], ts[:, :, 1], ts[:, :, 2], ts[:, :, 3]\n",
    "delta_year = tf.clip_by_value(year[:, -1:] - year, 0, 9)\n",
    "pos_tf = tf.concat([\n",
    "    position_expansion(delta_year),\n",
    "    position_expansion_1(month),\n",
    "    position_expansion_2(day),\n",
    "    position_expansion_3(dow),\n",
    "], axis=-1)\n",
    "\n",
    "pos_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionExpansion(nn.Module):\n",
    "    def __init__(self, periods: int, freqs: int):\n",
    "        super().__init__()\n",
    "        self.periods = periods\n",
    "        self.channels = freqs * 2\n",
    "\n",
    "        i = torch.arange(periods + 1).unsqueeze(1)  # shape: [periods+1, 1]\n",
    "        j = torch.arange(freqs).unsqueeze(0)        # shape: [1, freqs]\n",
    "        angles = math.pi / periods * (2 ** j) * (i - 1)  # i-1 matches TF\n",
    "\n",
    "        pe = torch.cat([torch.sin(angles), torch.cos(angles)], dim=1)  # [P+1, 2F]\n",
    "        self.register_buffer(\"embedding\", pe)\n",
    "\n",
    "    def forward(self, tc):\n",
    "        return self.embedding[tc]  # expects tc ∈ [0, periods]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tf tensors to numpy, then to torch\n",
    "year_pt, month_pt, day_pt, dow_pt = ts_pt[:, :, 0], ts_pt[:, :, 1], ts_pt[:, :, 2], ts_pt[:, :, 3]\n",
    "delta_year_pt = (year_pt[:, -1:] - year_pt).clamp(min=0, max=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 36])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_expansion_pt = PositionExpansion(10, 4)\n",
    "position_expansion_1_pt = PositionExpansion(12, 4)\n",
    "position_expansion_2_pt = PositionExpansion(31, 6)\n",
    "position_expansion_3_pt = PositionExpansion(7, 4)\n",
    "\n",
    "# Positional encoding\n",
    "pos_pt = torch.cat([\n",
    "    position_expansion_pt(delta_year_pt),\n",
    "    position_expansion_1_pt(month_pt),\n",
    "    position_expansion_2_pt(day_pt),\n",
    "    position_expansion_3_pt(dow_pt),\n",
    "], dim=-1)\n",
    "\n",
    "pos_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pos_pt.numpy(), pos_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scaling + History Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 72])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow code\n",
    "history_channels_tf = tf.expand_dims(history, -1)\n",
    "scale_tf, scaled_tf = custom_scaling(history_channels_tf, epsilon)\n",
    "embed_nopos_tf = no_pos_enc(scaled_tf)\n",
    "embed_pos_tf = for_pos_enc(scaled_tf) + tf.cast(pos_tf, tf.float32)\n",
    "embedded_tf = concat_embed([embed_nopos_tf, embed_pos_tf])\n",
    "embedded_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustScaler(nn.Module):\n",
    "    \"\"\"\n",
    "    RobustScaler normalizes input time series while ignoring outliers and missing values.\n",
    "    It masks out zeros, clips extreme values above mean + 2*std, rescales using\n",
    "    mean + std of clipped data, and clips final output to [0, 3].\n",
    "    This improves robustness in the presence of noise or missing data.\n",
    "    \"\"\"\n",
    "    def forward(self, x, epsilon):\n",
    "        # x: [B, T, 1]\n",
    "        B, T, _ = x.shape\n",
    "        x = x.squeeze(-1)  # → [B, T]\n",
    "        scale = torch.zeros((B, 1, 1), device=x.device)\n",
    "        scaled = torch.zeros((B, T, 1), device=x.device)\n",
    "\n",
    "        for b in range(B):\n",
    "            series = x[b]  # shape: [T]\n",
    "\n",
    "            # First mask and stats\n",
    "            non_zero = series[series != 0]\n",
    "            if non_zero.numel() == 0:\n",
    "                mean = std = torch.tensor(0.0, device=x.device)\n",
    "            else:\n",
    "                mean = non_zero.mean()\n",
    "                std = non_zero.std(unbiased=False)\n",
    "\n",
    "            upper = mean + 2 * std\n",
    "            clipped = torch.clamp(series, min=0.0, max=upper)\n",
    "\n",
    "            # Second pass stats\n",
    "            non_zero_clipped = clipped[clipped != 0]\n",
    "            if non_zero_clipped.numel() == 0:\n",
    "                mean_clip = std_clip = torch.tensor(0.0, device=x.device)\n",
    "            else:\n",
    "                mean_clip = non_zero_clipped.mean()\n",
    "                std_clip = non_zero_clipped.std(unbiased=False)\n",
    "\n",
    "            s = mean_clip + std_clip + epsilon\n",
    "            scale[b, 0, 0] = s\n",
    "            scaled[b, :, 0] = torch.clamp(series / s, 0.0, 3.0)\n",
    "\n",
    "        return scale, scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "# history_channels_torch = torch.from_numpy(history_channels.numpy())\n",
    "history_channels_pt = history_pt.unsqueeze(-1)\n",
    "scale_pt, scaled_pt = robust_scaler(history_channels_pt, epsilon)\n",
    "np.allclose(scale_pt, scale_tf, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# 1. Create PyTorch Linear layer\n",
    "expand_nopos_pt = nn.Sequential(\n",
    "    nn.Linear(1, 36),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# 2. Get TF weights \n",
    "# tf_weights: shape (1, 36), tf_bias: shape (36,)\n",
    "tf_weights = no_pos_enc.kernel.numpy().T  # TF: (1, 36) → PT: (36, 1)\n",
    "tf_bias    = no_pos_enc.bias.numpy()      # shape (36,)\n",
    "\n",
    "# 3. Copy weights to PyTorch layer\n",
    "linear_nopos = expand_nopos_pt[0]\n",
    "linear_nopos.weight.data.copy_(torch.from_numpy(tf_weights))\n",
    "linear_nopos.bias.data.copy_(torch.from_numpy(tf_bias))\n",
    "\n",
    "# 4. Test match\n",
    "embed_nopos_pt = expand_nopos_pt(scaled_pt)  # [B, T, 36]\n",
    "\n",
    "# 5. Compare\n",
    "print(\"Match:\", np.allclose(embed_nopos_pt.detach().numpy(), embed_nopos_tf.numpy(), atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_forpos_pt = nn.Sequential(\n",
    "    nn.Linear(1, 36),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "tf_weights = for_pos_enc.kernel.numpy().T\n",
    "tf_bias    = for_pos_enc.bias.numpy()\n",
    "\n",
    "linear_forpos = expand_forpos_pt[0]\n",
    "linear_forpos.weight.data.copy_(torch.from_numpy(tf_weights))\n",
    "linear_forpos.bias.data.copy_(torch.from_numpy(tf_bias))\n",
    "\n",
    "embed_pos_pt = expand_forpos_pt(scaled_pt) + pos_pt.float()\n",
    "np.allclose(embed_pos_pt.detach().numpy(), embed_pos_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_pt = torch.cat([embed_nopos_pt, embed_pos_pt], dim=-1)\n",
    "np.allclose(embedded.numpy(), embedded_pt.detach().numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Target Token & Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow code\n",
    "# 3. Target token\n",
    "target_year = tf.clip_by_value(year[:, -1:] - target_ts[:, :, 0], 0, 9)\n",
    "target_month, target_day, target_dow = target_ts[:, :, 1], target_ts[:, :, 2], target_ts[:, :, 3]\n",
    "target_pos_tf = tf.concat([\n",
    "    position_expansion(target_year),\n",
    "    position_expansion_1(target_month),\n",
    "    position_expansion_2(target_day),\n",
    "    position_expansion_3(target_dow),\n",
    "], axis=-1)\n",
    "task_embed_tf = embedding(task)\n",
    "target_token_tf = concat_embed([task_embed, task_embed + tf.cast(tf.squeeze(target_pos, 1), tf.float32)])\n",
    "target_token_tf.shape\n",
    "\n",
    "# 4. Append target token\n",
    "x_tf = append_target([embedded, tf.expand_dims(target_token, axis=1)])\n",
    "\n",
    "# 5. Mask\n",
    "seq_mask = tf.cast(year > 0, tf.bool)\n",
    "seq_mask = tf.pad(seq_mask, [[0, 0], [0, 1]], constant_values=True)\n",
    "mask_tf = tf.logical_and(tf.expand_dims(seq_mask, 1), tf.expand_dims(seq_mask, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract components from target_ts\n",
    "target_year_pt = (year_pt[:, -1:] - target_ts_pt[:, :, 0]).clamp(min=0, max=10)\n",
    "target_month_pt = target_ts_pt[:, :, 1]\n",
    "target_day_pt = target_ts_pt[:, :, 2]\n",
    "target_dow_pt = target_ts_pt[:, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Position Encodings\n",
    "target_pos_pt = torch.cat([\n",
    "    position_expansion_pt(target_year_pt),\n",
    "    position_expansion_1_pt(target_month_pt),\n",
    "    position_expansion_2_pt(target_day_pt),\n",
    "    position_expansion_3_pt(target_dow_pt),\n",
    "], dim=-1)  # shape: [B, 1, 36]\n",
    "np.allclose(target_pos_pt, target_pos_tf, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task embedding\n",
    "embedding_pt = nn.Embedding(num_embeddings=10, embedding_dim=36)\n",
    "embedding_pt.weight.data.copy_(torch.from_numpy(embedding.get_weights()[0]))\n",
    "task_embed_pt = embedding_pt(task_pt)\n",
    "np.allclose(task_embed_pt.detach().numpy(), task_embed_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target token\n",
    "target_token_pt = torch.cat([task_embed_pt,\n",
    "                             task_embed_pt + target_pos_pt.squeeze(1).float()], dim=-1).detach()\n",
    "np.allclose(target_token_pt.numpy(), target_token_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x: [B, T, D], target_token: [B, D]\n",
    "x_pt = torch.cat([embedded_pt, target_token_pt.unsqueeze(1)], dim=1) # -> [B, T+1, D]\n",
    "np.allclose(x_tf.numpy(), x_pt.detach().numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume `year` is shape [B, T] from ts[:, :, 0]\n",
    "seq_mask_pt = (year_pt > 0)  # → [B, T], bool\n",
    "seq_mask_pt = torch.cat([seq_mask_pt, torch.ones_like(seq_mask_pt[:, :1], dtype=torch.bool)], dim=1)  # [B, T+1]\n",
    "\n",
    "# Broadcast to [B, T+1, T+1]\n",
    "mask_pt = seq_mask_pt.unsqueeze(1) & seq_mask_pt.unsqueeze(2)\n",
    "\n",
    "np.allclose(mask_tf.numpy(), mask_pt.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Transformer Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 101, 288])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tf = transformer_block_0(x_tf, mask=mask_tf, training=False)\n",
    "# x_tf = transformer_block_1(x_tf, mask=mask_tf, training=False)\n",
    "# x_tf = x_tf[:, -1]\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=72, num_heads=4, value_dim=72):\n",
    "        super().__init__()\n",
    "        self.q_proj = nn.Linear(embed_dim, num_heads * value_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, num_heads * value_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, num_heads * value_dim)\n",
    "        self.out_proj = nn.Linear(num_heads * value_dim, embed_dim)\n",
    "        self.num_heads = num_heads\n",
    "        self.value_dim = value_dim\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, D = x.size()\n",
    "        H, V = self.num_heads, self.value_dim\n",
    "\n",
    "        q = self.q_proj(x).view(B, T, H, V).transpose(1, 2)\n",
    "        k = self.k_proj(x).view(B, T, H, V).transpose(1, 2)\n",
    "        v = self.v_proj(x).view(B, T, H, V).transpose(1, 2)\n",
    "\n",
    "        attn_scores = (q @ k.transpose(-2, -1)) / math.sqrt(V)\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(~mask[:, None, :, :], float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        context = attn_weights @ v\n",
    "        context = context.transpose(1, 2).reshape(B, T, H * V)\n",
    "\n",
    "        return self.out_proj(context)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=72, heads=4, value_dim=72):\n",
    "        super().__init__()\n",
    "        self.attn = CustomSelfAttention(d_model, heads, value_dim)\n",
    "        self.ff1 = nn.Linear(d_model, 4 * heads * value_dim)  # 4×288=1152\n",
    "        self.ff2 = nn.Linear(4 * heads * value_dim, heads * value_dim)  # → 288\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.attn(x, mask=mask)\n",
    "        x = self.activation(self.ff1(x))\n",
    "        x = self.activation(self.ff2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = TransformerBlock(d_model=72, heads=4, value_dim=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_mha_weights(pt_mha, tf_weights):\n",
    "    def reshape_tf_to_linear(w_keras, b_keras):\n",
    "        # w_keras: (in_dim, n_heads, head_dim) → (in_dim, out_dim)\n",
    "        w = w_keras.numpy().reshape(w_keras.shape[0], -1)\n",
    "        b = b_keras.numpy().reshape(-1)\n",
    "        return torch.from_numpy(w.T), torch.from_numpy(b)\n",
    "\n",
    "    # Query\n",
    "    q_w, q_b = reshape_tf_to_linear(tf_weights[0], tf_weights[1])\n",
    "    pt_mha.q_proj.weight.data.copy_(q_w)\n",
    "    pt_mha.q_proj.bias.data.copy_(q_b)\n",
    "\n",
    "    # Key\n",
    "    k_w, k_b = reshape_tf_to_linear(tf_weights[2], tf_weights[3])\n",
    "    pt_mha.k_proj.weight.data.copy_(k_w)\n",
    "    pt_mha.k_proj.bias.data.copy_(k_b)\n",
    "\n",
    "    # Value\n",
    "    v_w, v_b = reshape_tf_to_linear(tf_weights[4], tf_weights[5])\n",
    "    pt_mha.v_proj.weight.data.copy_(v_w)\n",
    "    pt_mha.v_proj.bias.data.copy_(v_b)\n",
    "\n",
    "    # Output projection: (n_heads, head_dim, out_dim)\n",
    "    out_w_tf = tf_weights[6].numpy().reshape(-1, tf_weights[6].shape[-1])  # (288, 72)\n",
    "    pt_mha.out_proj.weight.data.copy_(torch.from_numpy(out_w_tf.T))       # (72, 288)\n",
    "    pt_mha.out_proj.bias.data.copy_(torch.from_numpy(tf_weights[7].numpy()))\n",
    "\n",
    "def copy_transformer_block_weights(block_pt, block_tf):\n",
    "    copy_mha_weights(block_pt.attn, block_tf.attention.weights)\n",
    "\n",
    "    block_pt.ff1.weight.data.copy_(torch.from_numpy(block_tf.ff1.kernel.numpy().T))\n",
    "    block_pt.ff1.bias.data.copy_(torch.from_numpy(block_tf.ff1.bias.numpy()))\n",
    "\n",
    "    block_pt.ff2.weight.data.copy_(torch.from_numpy(block_tf.ff2.kernel.numpy().T))\n",
    "    block_pt.ff2.bias.data.copy_(torch.from_numpy(block_tf.ff2.bias.numpy()))\n",
    "\n",
    "copy_transformer_block_weights(block, transformer_block_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pt = block(x_pt, mask=mask_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(x_pt.detach().numpy(), x_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 101, 288])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tf = transformer_block_1(x_tf, mask=mask_tf, training=False)\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_1 = TransformerBlock(d_model=288, heads=4, value_dim=72)\n",
    "copy_transformer_block_weights(block_1, transformer_block_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pt = block_1(x_pt, mask=mask_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(x_pt.detach().numpy(), x_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 288])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tf = x_tf[:, -1]\n",
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 288])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = x_pt[:, -1]\n",
    "x_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(x_pt.detach().numpy(), x_tf.numpy(), atol=1e-5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.0238485],\n",
       "       [1.0556059]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow code\n",
    "rescaled_tf = final_output(x_tf) * tf.squeeze(scale_tf[:, -1:], axis=-1)\n",
    "rescaled_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_pt = nn.Sequential(\n",
    "    nn.Linear(288, 1),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "tf_weights = final_output.kernel.numpy().T\n",
    "tf_bias    = final_output.bias.numpy()\n",
    "\n",
    "linear_final = final_output_pt[0]\n",
    "linear_final.weight.data.copy_(torch.from_numpy(tf_weights))\n",
    "linear_final.bias.data.copy_(torch.from_numpy(tf_bias))\n",
    "\n",
    "rescaled_pt = final_output_pt(x_pt) * scale_pt[:, -1, 0:1]\n",
    "\n",
    "np.allclose(rescaled_pt.detach().numpy(), rescaled_tf.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(rescaled_pt.detach().numpy(), full_result.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(scale_pt[:, -1, 0:1].detach().numpy(), full_scale.numpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TASKS = 10\n",
    "YEAR = 0\n",
    "MONTH = 1\n",
    "DAY = 2\n",
    "DOW = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaling(nn.Module):\n",
    "    \"\"\"\n",
    "    Used to normalize the historical input series before encoding.\n",
    "    It ensures that time series values are on a comparable scale across samples\n",
    "    \"\"\"\n",
    "    def __init__(self, method='robust'):\n",
    "        super().__init__()\n",
    "        if method == 'robust':\n",
    "            self.scaler = RobustScaler()\n",
    "        elif method == 'max':\n",
    "            self.scaler = MaxScaler()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scaling method: {method}\")\n",
    "\n",
    "    def forward(self, history_channels, epsilon):\n",
    "        return self.scaler(history_channels, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastPFN(nn.Module):\n",
    "    def __init__(self, epsilon=1e-4, scaler='robust'):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.pos_year = PositionExpansion(10, 4)\n",
    "        self.pos_month = PositionExpansion(12, 4)\n",
    "        self.pos_day = PositionExpansion(31, 6)\n",
    "        self.pos_dow = PositionExpansion(7, 4)\n",
    "        self.scaler = CustomScaling(scaler)\n",
    "        self.embed_size = sum(emb.channels for emb in (self.pos_year, self.pos_month, self.pos_day, self.pos_dow))\n",
    "        self.expand_target_nopos = nn.Sequential(nn.Linear(1, 36),\n",
    "                                                 nn.ReLU())\n",
    "        self.expand_target_forpos = nn.Sequential(nn.Linear(1, 36),\n",
    "                                                  nn.ReLU())\n",
    "        self.target_marker = nn.Embedding(NUM_TASKS, self.embed_size)\n",
    "        # Transformer Blocks\n",
    "        self.d_model = self.embed_size * 2\n",
    "        self.encoder0 = TransformerBlock(d_model=self.d_model)\n",
    "        self.encoder1 = TransformerBlock(d_model=self.d_model * 4)\n",
    "        self.final_output = nn.Sequential(\n",
    "            nn.Linear(self.d_model * 4, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def tc(ts, time_index):\n",
    "        return ts[:, :, time_index]\n",
    "    def forward(self, x):\n",
    "        ts, history, target_ts, task = x['ts'], x['history'], x['target_ts'], x['task']\n",
    "        \n",
    "        # Build position encodings\n",
    "        year = self.tc(ts, YEAR)\n",
    "        delta_year = (year[:, -1:] - year).clamp(min=0, max=self.pos_year.periods)\n",
    "        pos_embedding = torch.cat([\n",
    "            self.pos_year(delta_year_pt),\n",
    "            self.pos_month(self.tc(ts, MONTH)),\n",
    "            self.pos_day(self.tc(ts, DAY)),\n",
    "            self.pos_dow(self.tc(ts, DOW)),\n",
    "            ], dim=-1)\n",
    "        \n",
    "        # Embed history\n",
    "        history_channels = history.unsqueeze(-1)\n",
    "        scale, scaled = self.scaler(history_channels, self.epsilon)\n",
    "        embed_nopos = self.expand_target_nopos(scaled)\n",
    "        embed_pos = self.expand_target_forpos(scaled) + pos_embedding\n",
    "        embedded = torch.cat([embed_nopos, embed_pos], dim=-1)\n",
    "        \n",
    "        # Embed target\n",
    "        target_year = (year[:, -1:] - self.tc(target_ts, YEAR)).clamp(min=0, max=self.pos_year.periods)\n",
    "        target_pos_embed = torch.cat([\n",
    "            self.pos_year(target_year),\n",
    "            self.pos_month(self.tc(target_ts, MONTH)),\n",
    "            self.pos_day(self.tc(target_ts, DAY)),\n",
    "            self.pos_dow(self.tc(target_ts, DOW))\n",
    "            ], dim=-1)\n",
    "        target_pos_embed = target_pos_embed.squeeze(1)\n",
    "        task_embed = self.target_marker(task)\n",
    "        target = torch.cat([task_embed, task_embed + target_pos_embed], dim=-1)\n",
    "        \n",
    "        # Mask\n",
    "        seq_mask = (year > 0)  # → [B, T], bool\n",
    "        seq_mask = torch.cat([seq_mask, torch.ones_like(seq_mask[:, :1], dtype=torch.bool)], dim=1)  # [B, T+1]\n",
    "\n",
    "        # Broadcast to [B, T+1, T+1]\n",
    "        mask = seq_mask.unsqueeze(1) & seq_mask.unsqueeze(2)\n",
    "        \n",
    "        x = torch.cat([embedded, target.unsqueeze(1)], dim=1)\n",
    "        x = self.encoder0(x, mask=mask)\n",
    "        x = self.encoder1(x, mask=mask)\n",
    "        scale = scale[:, -1, 0:1]\n",
    "        result = self.final_output(x[:, -1, :]) * scale\n",
    "        return {'result': result, 'scale': scale}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastPFN(\n",
       "  (pos_year): PositionExpansion()\n",
       "  (pos_month): PositionExpansion()\n",
       "  (pos_day): PositionExpansion()\n",
       "  (pos_dow): PositionExpansion()\n",
       "  (scaler): CustomScaling(\n",
       "    (scaler): RobustScaler()\n",
       "  )\n",
       "  (expand_target_nopos): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=36, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (expand_target_forpos): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=36, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (target_marker): Embedding(10, 36)\n",
       "  (encoder0): TransformerBlock(\n",
       "    (attn): CustomSelfAttention(\n",
       "      (q_proj): Linear(in_features=72, out_features=288, bias=True)\n",
       "      (k_proj): Linear(in_features=72, out_features=288, bias=True)\n",
       "      (v_proj): Linear(in_features=72, out_features=288, bias=True)\n",
       "      (out_proj): Linear(in_features=288, out_features=72, bias=True)\n",
       "    )\n",
       "    (ff1): Linear(in_features=72, out_features=1152, bias=True)\n",
       "    (ff2): Linear(in_features=1152, out_features=288, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "  )\n",
       "  (encoder1): TransformerBlock(\n",
       "    (attn): CustomSelfAttention(\n",
       "      (q_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      (k_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      (v_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      (out_proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "    )\n",
       "    (ff1): Linear(in_features=288, out_features=1152, bias=True)\n",
       "    (ff2): Linear(in_features=1152, out_features=288, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "  )\n",
       "  (final_output): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=1, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pt = ForecastPFN()\n",
    "model_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': tensor([[1.0238],\n",
       "         [1.0556]], grad_fn=<MulBackward0>),\n",
       " 'scale': tensor([[1.2982],\n",
       "         [1.3833]])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy weights from TF model\n",
    "linear_nopos = model_pt.expand_target_nopos[0]\n",
    "linear_nopos.weight.data.copy_(torch.from_numpy(no_pos_enc.kernel.numpy().T))\n",
    "linear_nopos.bias.data.copy_(torch.from_numpy(no_pos_enc.bias.numpy().T))\n",
    "\n",
    "linear_forpos = model_pt.expand_target_forpos[0]\n",
    "linear_forpos.weight.data.copy_(torch.from_numpy(for_pos_enc.kernel.numpy().T))\n",
    "linear_forpos.bias.data.copy_(torch.from_numpy(for_pos_enc.bias.numpy()))\n",
    "\n",
    "model_pt.target_marker.weight.data.copy_(torch.from_numpy(embedding.get_weights()[0]))\n",
    "\n",
    "pt_block0 = model_pt.encoder0\n",
    "pt_block1 = model_pt.encoder1\n",
    "copy_transformer_block_weights(pt_block0, transformer_block_0)\n",
    "copy_transformer_block_weights(pt_block1, transformer_block_1)\n",
    "\n",
    "linear_final = model_pt.final_output[0]\n",
    "linear_final.weight.data.copy_(torch.from_numpy(final_output.kernel.numpy().T))\n",
    "linear_final.bias.data.copy_(torch.from_numpy(final_output.bias.numpy()))\n",
    "\n",
    "model_pt(torch_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[1.2981894],\n",
       "        [1.3832798]], dtype=float32)>,\n",
       " 'result': <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[1.0238485],\n",
       "        [1.0556059]], dtype=float32)>}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify pytorch version vs. original tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result match: True\n",
      "Scale match : True\n"
     ]
    }
   ],
   "source": [
    "pt_output = model_pt(torch_input)\n",
    "# TensorFlow output\n",
    "tf_result = output['result'].numpy()\n",
    "tf_scale  = output['scale'].numpy()\n",
    "\n",
    "# PyTorch output\n",
    "pt_result = pt_output['result'].detach().numpy()\n",
    "pt_scale  = pt_output['scale'].detach().numpy()\n",
    "\n",
    "# Comparison\n",
    "print(\"Result match:\", np.allclose(tf_result, pt_result, atol=1e-5))\n",
    "print(\"Scale match :\", np.allclose(tf_scale, pt_scale, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_pt.state_dict(), \"forecastpfn_pytorch.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
